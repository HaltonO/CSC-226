{
    "docs": [
        {
            "location": "/", 
            "text": "CSC 226: Algorithms and Data Structures: II\n\n\nWebsite\n\n\nhttp://www.csc.uvic.ca/courses/csc226\n\n\nInstructor\n\n\n\n\nName: Frank Ruskey \n\n\nEmail: ruskey at uvic.ca \n\n\nOffice: ECS 564 \n\n\nOffice Hours: MR 1:30 - 3:00 p.m. (tentative)\n\n\n\n\nLecture Schedule\n\n\nMR 8:30 - 9:50 a.m.     HSD A240 \n\n\nTextbooks\n\n\nRequired:   \nAlgorithms (Fourth Edition) Robert Sedgewick and Kevin Wayne Addison-Wesley, 2011 \n\n\nI-clickers\n\n\nStudents are required to bring their iClickers to each lecture; the clickers will not be used in the labs.\n\n\nGrading\n\n\n\n\n\n\n\n\nTask\n\n\nWeight\n\n\n\n\n\n\n\n\n\n\nParticipation\n\n\n5%\n\n\n\n\n\n\nAssignments\n\n\n25%\n\n\n\n\n\n\nMidterm\n\n\n20%\n\n\n\n\n\n\nFinal\n\n\n50%\n\n\n\n\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\nAssignment #\n\n\nWeight\n\n\nDue Date\n\n\n\n\n\n\n\n\n\n\n1\n\n\n5%\n\n\nJanuary 23\n\n\n\n\n\n\n2\n\n\n5%\n\n\nFebruary 5\n\n\n\n\n\n\n3\n\n\n5%\n\n\nMarch 18\n\n\n\n\n\n\n4\n\n\n5%\n\n\nApril 4\n\n\n\n\n\n\n5\n\n\n5%\n\n\nMarch 25", 
            "title": "Home"
        }, 
        {
            "location": "/#csc-226-algorithms-and-data-structures-ii", 
            "text": "", 
            "title": "CSC 226: Algorithms and Data Structures: II"
        }, 
        {
            "location": "/#website", 
            "text": "http://www.csc.uvic.ca/courses/csc226", 
            "title": "Website"
        }, 
        {
            "location": "/#instructor", 
            "text": "Name: Frank Ruskey   Email: ruskey at uvic.ca   Office: ECS 564   Office Hours: MR 1:30 - 3:00 p.m. (tentative)", 
            "title": "Instructor"
        }, 
        {
            "location": "/#lecture-schedule", 
            "text": "MR 8:30 - 9:50 a.m.     HSD A240", 
            "title": "Lecture Schedule"
        }, 
        {
            "location": "/#textbooks", 
            "text": "Required:    Algorithms (Fourth Edition) Robert Sedgewick and Kevin Wayne Addison-Wesley, 2011", 
            "title": "Textbooks"
        }, 
        {
            "location": "/#i-clickers", 
            "text": "Students are required to bring their iClickers to each lecture; the clickers will not be used in the labs.", 
            "title": "I-clickers"
        }, 
        {
            "location": "/#grading", 
            "text": "Task  Weight      Participation  5%    Assignments  25%    Midterm  20%    Final  50%", 
            "title": "Grading"
        }, 
        {
            "location": "/#assignments", 
            "text": "Assignment #  Weight  Due Date      1  5%  January 23    2  5%  February 5    3  5%  March 18    4  5%  April 4    5  5%  March 25", 
            "title": "Assignments"
        }, 
        {
            "location": "/2016-01-04/", 
            "text": "Lecture 1 - Notes\n\n\nJanuary 4, 2016\n\n\nTrees\n\n\nTopological trees\n\n\n\n\nFree trees\n\n\nRooted trees\n\n\nOrdered trees\n\n\nBinary trees\n\n\n\n\nFree Trees\n\n\n\n\nA free tree is the most general kind of tree.\n\n\n\n\ndefinition\n: A \nfree tree\n is an acyclic connected graph.\n\n\n\n\nAcyclic\n: No cycles\n\n\nConnected\n: There is a path between any two vertices\n\n\n\n\n\n\nA \nfree tree\n with $n$ nodes always has $e = n-1$ edges.\n\n\nExample\n\n\nHow many trees are there with $n = 3$ vertices?\n\n\nSolution\n\n\nOne. See above.\n\n\nRooted Trees\n\n\ndefinition\n: A \nrooted tree\n is a tree in which some node is distinguished as the root.\n\n\n\n\nExample\n\n\nHow many trees are there with $n = 4$ vertices?\n\n\nSolution\n\n\nFour. See above.\n\n\nOrdered Trees\n\n\ndefinition\n: An \nordered tree\n is a rooted tree in which the subtrees are ordered recursively.\n\n\nThe tree is ordered \"horizontally\" (because that's how levels work).\n\n\n\n\nBinary Trees\n\n\ndefinition\n: A \nBinary Tree\n is either empty or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint binary trees.\n\n\n\n\nExample\n\n\nHow many trees are there with $n = 3$ vertices?\n\n\nSolution\n\n\nFive. See above.\n\n\nExtended Binary Trees\n\n\ndefinition\n: An \nExtended Binary Tree\n is either a leaf node or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint extended binary trees.\n\n\n\n\n\n\nA binary tree where each node has two children called leaves\n\n\nA binary tree in which special nodes are added wherever a null subtree was present in the original tree so that each node in the original tree will always have 2 children (excluding an empty tree)\n\n\n\n\nAn \nExtended Binary Tree\n with $n$ internal nodes has $l = n + 1$ leaves.\n\n\nApplications\n\n\n\n\nBinary Search Trees - Binary Tree\n\n\nDecision Trees - Extended Binary Tree\n\n\n\n\nRepresentations\n\n\nBinary Trees\n\n\nEach node represented with a data value and left and right child nodes.\n\n\n\n\nclass Node {\n    Object data;\n    Node leftChild;\n    Node rightChild;\n}\n\n\n\n\nTree Traversal\n\n\nPreorder\n\n\n\n\nIn-order\n\n\n\n\nPostorder\n\n\n\n\nConverting a Ordered Forest into a Binary Tree\n\n\n\n\n\n\nUse the root of the ordered tree as the root of the binary tree\n\n\nThe leftmost node in the ordered tree becomes the left child of the parent node\n\n\nContinue finding children of the parent node insert it as the right subtree of leftmost child\n\n\nRepeat this process for all of the nodes\n\n\nNodes that have children in the ordered tree representation will have a left child in the binary tree representation\n\n\nIf a node has a right child in the binary tree representation it has siblings in the ordered tree representation", 
            "title": "2016 01 04"
        }, 
        {
            "location": "/2016-01-04/#lecture-1-notes", 
            "text": "January 4, 2016", 
            "title": "Lecture 1 - Notes"
        }, 
        {
            "location": "/2016-01-04/#trees", 
            "text": "Topological trees   Free trees  Rooted trees  Ordered trees  Binary trees   Free Trees   A free tree is the most general kind of tree.   definition : A  free tree  is an acyclic connected graph.   Acyclic : No cycles  Connected : There is a path between any two vertices    A  free tree  with $n$ nodes always has $e = n-1$ edges.  Example  How many trees are there with $n = 3$ vertices?  Solution  One. See above.  Rooted Trees  definition : A  rooted tree  is a tree in which some node is distinguished as the root.   Example  How many trees are there with $n = 4$ vertices?  Solution  Four. See above.  Ordered Trees  definition : An  ordered tree  is a rooted tree in which the subtrees are ordered recursively.  The tree is ordered \"horizontally\" (because that's how levels work).   Binary Trees  definition : A  Binary Tree  is either empty or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint binary trees.   Example  How many trees are there with $n = 3$ vertices?  Solution  Five. See above.  Extended Binary Trees  definition : An  Extended Binary Tree  is either a leaf node or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint extended binary trees.    A binary tree where each node has two children called leaves  A binary tree in which special nodes are added wherever a null subtree was present in the original tree so that each node in the original tree will always have 2 children (excluding an empty tree)   An  Extended Binary Tree  with $n$ internal nodes has $l = n + 1$ leaves.", 
            "title": "Trees"
        }, 
        {
            "location": "/2016-01-04/#applications", 
            "text": "Binary Search Trees - Binary Tree  Decision Trees - Extended Binary Tree", 
            "title": "Applications"
        }, 
        {
            "location": "/2016-01-04/#representations", 
            "text": "Binary Trees  Each node represented with a data value and left and right child nodes.   class Node {\n    Object data;\n    Node leftChild;\n    Node rightChild;\n}", 
            "title": "Representations"
        }, 
        {
            "location": "/2016-01-04/#tree-traversal", 
            "text": "Preorder   In-order   Postorder", 
            "title": "Tree Traversal"
        }, 
        {
            "location": "/2016-01-04/#converting-a-ordered-forest-into-a-binary-tree", 
            "text": "Use the root of the ordered tree as the root of the binary tree  The leftmost node in the ordered tree becomes the left child of the parent node  Continue finding children of the parent node insert it as the right subtree of leftmost child  Repeat this process for all of the nodes  Nodes that have children in the ordered tree representation will have a left child in the binary tree representation  If a node has a right child in the binary tree representation it has siblings in the ordered tree representation", 
            "title": "Converting a Ordered Forest into a Binary Tree"
        }, 
        {
            "location": "/2016-01-07/", 
            "text": "Lecture 2 - Notes\n\n\nJanuary 7, 2016\n\n\nEncoding Trees\n\n\nMark internal nodes with ones and leaves with zeros. We then do a preorder traversal. This gives us a sequence, e.g.,\n\n\n\n\n\n    11100011000\n\n\n\n\n\nThis \ntree sequence\n let's us create a well formed parenthesis string.\n\n\n\n\n\n    \\underset{1}(\\underset{1}(\\underset{1}(\\underset{0})\\underset{0})\\underset{0})\\underset{1}(\\underset{1}( \\underset{0}) \\underset{0})\n\n\n\n\n\nThis parenthesis string is \nunique\n to that tree.\n\n\nUnion Find\n\n\nGiven a set of $N$ object we would like to,\n\n\n\n\nConnect two objects\n\n\nTest if theirs a path between two objects\n\n\n\n\nTo find out if a \nstatic\n graph is connected you could use DFS or BFS which is $O(|V| + |E|)$.\n\n\nIn this \ndynamic\n environment we are adding edges to the graph. We assume \"is connected to\" to be an equivalence relation. We will therefor use sets to encapsulate components, when creating edges we will check which set each node is in then join the two sets.\n\n\nclass UF\n{\n    UF (int n)\n\n    void union(int p,  int q)\n\n    int find(int p)\n\n    boolean connected(int p, int q)\n}\n\n\n\n\nQuick Find\n\n\nData structure\n\n\n\n\nInteger array \nid[]\n of length \nN\n\n\nInterpretation \nid[p]\n is the id of the component containing \np\n\n\n\n\nExample\n\n\n          0 1 2 3 4 5 6 7 8 9\n    id = [0,1,1,8,8,0,0,1,8,8]\n\n\n\n\nSo 0, 5 and 6 are connected, etc.\n\n\n\n\nfind(p)\n: Lookup \np\n by index\n\n\nconnected(p,q)\n: Do \np\n and \nq\n have the same id?\n\n\nunion(p,q)\n: Change all entries were id is \nid[p]\n to \nid[q]\n\n\n\n\nQuick Union\n\n\nData Structure\n\n\n\n\nInteger array \nid[]\n of length \nN\n\n\nInterpretation \nid[i]\n is the parent of \ni\n\n\nRoot of \ni\n is \nid[id[...id[i]...]]\n\n\n\n\n          0 1 2 3 4 5 6 7 8 9\n    id = [0,1,9,4,9,6,6,7,8,9]\n\n\n\n\n\n\nfind(p)\n: What is the root of \np\n\n\nconnected(p,q)\n: Do \np\n and \nq\n have the same root?\n\n\nunion(p,q)\n: Set the id of \np\n's root to the id of \nq\n's root\n\n\n\n\nIssues\n\n\nBoth of the these operation are too expensive,\n\n\n\n\n\n\n\n\nAlgorithm\n\n\nintialize\n\n\nunion\n\n\nfind\n\n\nconnected\n\n\n\n\n\n\n\n\n\n\nQuick Find\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(1)$\n\n\n$O(1)$\n\n\n\n\n\n\nQuick Union\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n\n\n\n\n\n\nQuick Find\n\n\n\n\nUnions are expensive\n\n\nTrees are flat but it's expensive to eep them flat\n\n\n\n\nQuick Union\n\n\n\n\nTrees can get very tall\n\n\nFind/connect is expensive\n\n\n\n\nWeighted Quick Union\n\n\n\n\nModify Quick Union to avoid tall trees\n\n\nKeep track of the size of each tree\n\n\nBalance by linking smaller tree to root of larger tree\n\n\n\n\nData Structure\n\n\nSame as Quick Union but maintain an extra array \nsz[i]\n that counts the number of objects rooted at \ni\n.\n\n\n\n\nfind(p)\n/\nconnected(p,q)\n: Same as Quick Union\n\n\nUnion(p,q)\n: Link the smaller tree to the larger tree, update \nsz[]\n\n\n\n\nEfficiency\n\n\n\n\n\n\n\n\nAlgorithm\n\n\ninitialize\n\n\nunion\n\n\nfind\n\n\nconnected\n\n\n\n\n\n\n\n\n\n\nQuick Find\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(1)$\n\n\n$O(1)$\n\n\n\n\n\n\nQuick Union\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n\n\n\n\nWeighted Quick Union\n\n\n$O(N)$\n\n\n$O(\\lg{N})$\n\n\n$O(\\lg{N})$\n\n\n$O(\\lg{N})$", 
            "title": "2016 01 07"
        }, 
        {
            "location": "/2016-01-07/#lecture-2-notes", 
            "text": "January 7, 2016", 
            "title": "Lecture 2 - Notes"
        }, 
        {
            "location": "/2016-01-07/#encoding-trees", 
            "text": "Mark internal nodes with ones and leaves with zeros. We then do a preorder traversal. This gives us a sequence, e.g.,   \n    11100011000   This  tree sequence  let's us create a well formed parenthesis string.   \n    \\underset{1}(\\underset{1}(\\underset{1}(\\underset{0})\\underset{0})\\underset{0})\\underset{1}(\\underset{1}( \\underset{0}) \\underset{0})   This parenthesis string is  unique  to that tree.", 
            "title": "Encoding Trees"
        }, 
        {
            "location": "/2016-01-07/#union-find", 
            "text": "Given a set of $N$ object we would like to,   Connect two objects  Test if theirs a path between two objects   To find out if a  static  graph is connected you could use DFS or BFS which is $O(|V| + |E|)$.  In this  dynamic  environment we are adding edges to the graph. We assume \"is connected to\" to be an equivalence relation. We will therefor use sets to encapsulate components, when creating edges we will check which set each node is in then join the two sets.  class UF\n{\n    UF (int n)\n\n    void union(int p,  int q)\n\n    int find(int p)\n\n    boolean connected(int p, int q)\n}  Quick Find  Data structure   Integer array  id[]  of length  N  Interpretation  id[p]  is the id of the component containing  p   Example            0 1 2 3 4 5 6 7 8 9\n    id = [0,1,1,8,8,0,0,1,8,8]  So 0, 5 and 6 are connected, etc.   find(p) : Lookup  p  by index  connected(p,q) : Do  p  and  q  have the same id?  union(p,q) : Change all entries were id is  id[p]  to  id[q]   Quick Union  Data Structure   Integer array  id[]  of length  N  Interpretation  id[i]  is the parent of  i  Root of  i  is  id[id[...id[i]...]]             0 1 2 3 4 5 6 7 8 9\n    id = [0,1,9,4,9,6,6,7,8,9]   find(p) : What is the root of  p  connected(p,q) : Do  p  and  q  have the same root?  union(p,q) : Set the id of  p 's root to the id of  q 's root   Issues  Both of the these operation are too expensive,     Algorithm  intialize  union  find  connected      Quick Find  $O(N)$  $O(N)$  $O(1)$  $O(1)$    Quick Union  $O(N)$  $O(N)$  $O(N)$  $O(N)$     Quick Find   Unions are expensive  Trees are flat but it's expensive to eep them flat   Quick Union   Trees can get very tall  Find/connect is expensive   Weighted Quick Union   Modify Quick Union to avoid tall trees  Keep track of the size of each tree  Balance by linking smaller tree to root of larger tree   Data Structure  Same as Quick Union but maintain an extra array  sz[i]  that counts the number of objects rooted at  i .   find(p) / connected(p,q) : Same as Quick Union  Union(p,q) : Link the smaller tree to the larger tree, update  sz[]   Efficiency     Algorithm  initialize  union  find  connected      Quick Find  $O(N)$  $O(N)$  $O(1)$  $O(1)$    Quick Union  $O(N)$  $O(N)$  $O(N)$  $O(N)$    Weighted Quick Union  $O(N)$  $O(\\lg{N})$  $O(\\lg{N})$  $O(\\lg{N})$", 
            "title": "Union Find"
        }, 
        {
            "location": "/2016-01-11/", 
            "text": "Lecture 3 - Notes\n\n\nJanuary 11, 2016\n\n\nWeighted Quick Union --- Continued\n\n\nUnion\n\n\nProposition\n, The depth of any node is $\\le \\lg N$.\n\n\nProof:\n\n\nThe depth goes up (by 1) only on a union with $x$ where $x$ is in the smaller tree,\n\n\n\n\nthe size of the tree containing $x$ is at least twice as large on such a union\n\n\nthe size of a tree can double at most $\\lg N$ times\n\n\n\n\nUsing \nrank\n instead of node count to track the size of the trees can reduce the space complexity since the maximum bit length for the rank is $\\le \\lg(\\lg(N))$\n\n\nCompression\n\n\nWe make nodes along the find path point to the root.\n\n\nTo do this \nwith two passes\n we can perform a second loop setting every node to the root.\n\n\nTo do this \nwith one path\n this make every other node in the path point to it's grandparent.\n\n\npublic int find(int i)\n{\n   while (i != id[i])\n   {\n      id[i] = id[id[i]]; //\n-- Set the Grandparent\n      i = id[i]; \n   }\n   return i;\n}\n\n\n\n\nComparison Based Sorting\n\n\nIn \nComparison Based Sorting\n like,\n\n\n\n\nMergesort\n\n\nQuicksort\n\n\nHeapsort\n\n\n\n\nLet's say we are sorting something \nsort([a,b,c])\n,\n\n\n\n\nThis comparison tree has 6 leaves. In general it has to be $\\ge N!$ (because that's how many possible combinations there are).\n\n\nThe height is the worst case number of comparisons, in this case 3. What is the minimum height $h$ of an extended binary tree with $n$ leaves?\n\n\n\n\n\\begin{align}\n    n &\\le 2^h \\newline\n    \\lceil \\lg n \\rceil &\\le h\n\\end{align}\n\n\n\n\nTherefore the height for sorting is $\\ge \\lceil \\lg{N!} \\rceil$. We can bound $N!$ with,\n\n\n\n\n\\begin{align}\n    \\left( \\frac{n}{2} \\right) ^ \\frac{n}{2} \\le N! \\le N^N\n\\end{align}\n\n\n\n\nand by taking the log,\n\n\n\n\n\\begin{align}\n    \\frac{n}{2} \\lg \\left( \\frac{n}{2} \\right) \\le \\lg{N!} \\le N \\lg {N}\n\\end{align}\n\n\n\n\nSo comparison based sorting requires $\\Omega (N \\lg N)$ comparisons.", 
            "title": "2016 01 11"
        }, 
        {
            "location": "/2016-01-11/#lecture-3-notes", 
            "text": "January 11, 2016", 
            "title": "Lecture 3 - Notes"
        }, 
        {
            "location": "/2016-01-11/#weighted-quick-union-continued", 
            "text": "Union  Proposition , The depth of any node is $\\le \\lg N$.  Proof:  The depth goes up (by 1) only on a union with $x$ where $x$ is in the smaller tree,   the size of the tree containing $x$ is at least twice as large on such a union  the size of a tree can double at most $\\lg N$ times   Using  rank  instead of node count to track the size of the trees can reduce the space complexity since the maximum bit length for the rank is $\\le \\lg(\\lg(N))$  Compression  We make nodes along the find path point to the root.  To do this  with two passes  we can perform a second loop setting every node to the root.  To do this  with one path  this make every other node in the path point to it's grandparent.  public int find(int i)\n{\n   while (i != id[i])\n   {\n      id[i] = id[id[i]]; // -- Set the Grandparent\n      i = id[i]; \n   }\n   return i;\n}", 
            "title": "Weighted Quick Union --- Continued"
        }, 
        {
            "location": "/2016-01-11/#comparison-based-sorting", 
            "text": "In  Comparison Based Sorting  like,   Mergesort  Quicksort  Heapsort   Let's say we are sorting something  sort([a,b,c]) ,   This comparison tree has 6 leaves. In general it has to be $\\ge N!$ (because that's how many possible combinations there are).  The height is the worst case number of comparisons, in this case 3. What is the minimum height $h$ of an extended binary tree with $n$ leaves?   \\begin{align}\n    n &\\le 2^h \\newline\n    \\lceil \\lg n \\rceil &\\le h\n\\end{align}   Therefore the height for sorting is $\\ge \\lceil \\lg{N!} \\rceil$. We can bound $N!$ with,   \\begin{align}\n    \\left( \\frac{n}{2} \\right) ^ \\frac{n}{2} \\le N! \\le N^N\n\\end{align}   and by taking the log,   \\begin{align}\n    \\frac{n}{2} \\lg \\left( \\frac{n}{2} \\right) \\le \\lg{N!} \\le N \\lg {N}\n\\end{align}   So comparison based sorting requires $\\Omega (N \\lg N)$ comparisons.", 
            "title": "Comparison Based Sorting"
        }, 
        {
            "location": "/2016-01-14/", 
            "text": "Lecture 4 - Notes\n\n\nJanuary 14, 2016\n  \n\n\nComparison Based Lower Bounds\n\n\nIf we are solving a problem using only comparisons and there are $n$ possible outcomes, then in the worst case $\\lceil \\lg{n} \\rceil$ comparisons are required.\n\n\nExample\n\n\nSuppose we have an array of $n$ sorted elements and we want to find some element $x$.\n\n\nWe could use binary search which will give us $O(\\lg n)$. Instead we could use interpolation search $O\\left(\\lg{\\left(\\lg{n}\\right)}\\right)$.\n\n\nSorting\n\n\nLet say we're sorting again,\n\n\n\n\nA sorting algorithm can be viewed as transforming a totally unordered set into a totally ordered set. Below we have converter the sorting diagram into a graph of partial order sets.\n\n\n\n\nPartial Order Sets\n\n\ndefinition\n: A binary relation ($\\le$) on a set $S$ is a \npartial order\n if,\n\n\n\n\n$a \\le a$ for all $a \\in S$ (reflexive)\n\n\n$a \\le b$ and $b \\le a$ implies $a = b$ (anti-symmetric)\n\n\n$a \\le b$ and $b \\le c$ implies $a \\le c$ (transitive)\n\n\n\n\nA partially ordered set is sometimes called a \nposet\n.\n\n\nSome other variants of this ordering are,\n\n\n\n\n$\\le$ Weak Partial Order\n\n\n$\\lt$ Strick Partial Order\n\n\n$\\equiv$ Equivalence Relations\n\n\n\n\nHasse Diagram\n\n\ndefinition\n: A \nHasse Diagram\n of a partially ordered set (poset) $S$ is a graph $G = (S,E)$ where $(a,c) \\in E$ if and only if $a \\lt c$ and there is no $b$ such that $a \\lt b \\lt c$\n\n\nThese posets can be combined into a \nHasse diagram\n. Below are the Hasse diagrams for sorts of size 3 and 4.", 
            "title": "2016 01 14"
        }, 
        {
            "location": "/2016-01-14/#lecture-4-notes", 
            "text": "January 14, 2016", 
            "title": "Lecture 4 - Notes"
        }, 
        {
            "location": "/2016-01-14/#comparison-based-lower-bounds", 
            "text": "If we are solving a problem using only comparisons and there are $n$ possible outcomes, then in the worst case $\\lceil \\lg{n} \\rceil$ comparisons are required.  Example  Suppose we have an array of $n$ sorted elements and we want to find some element $x$.  We could use binary search which will give us $O(\\lg n)$. Instead we could use interpolation search $O\\left(\\lg{\\left(\\lg{n}\\right)}\\right)$.  Sorting  Let say we're sorting again,   A sorting algorithm can be viewed as transforming a totally unordered set into a totally ordered set. Below we have converter the sorting diagram into a graph of partial order sets.   Partial Order Sets  definition : A binary relation ($\\le$) on a set $S$ is a  partial order  if,   $a \\le a$ for all $a \\in S$ (reflexive)  $a \\le b$ and $b \\le a$ implies $a = b$ (anti-symmetric)  $a \\le b$ and $b \\le c$ implies $a \\le c$ (transitive)   A partially ordered set is sometimes called a  poset .  Some other variants of this ordering are,   $\\le$ Weak Partial Order  $\\lt$ Strick Partial Order  $\\equiv$ Equivalence Relations   Hasse Diagram  definition : A  Hasse Diagram  of a partially ordered set (poset) $S$ is a graph $G = (S,E)$ where $(a,c) \\in E$ if and only if $a \\lt c$ and there is no $b$ such that $a \\lt b \\lt c$  These posets can be combined into a  Hasse diagram . Below are the Hasse diagrams for sorts of size 3 and 4.", 
            "title": "Comparison Based Lower Bounds"
        }
    ]
}