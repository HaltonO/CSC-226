{
    "docs": [
        {
            "location": "/", 
            "text": "CSC 226\n\n\nCourse Website\n\n\nTextbook Website\n\n\nInstructor\n\n\n\n\nName\n: Frank Ruskey \n\n\nEmail\n: \nruskey@uvic.ca\n\n\nOffice\n: ECS 564 \n\n\nOffice Hours\n: Mondays and Thursdays, 1:30 PM - 3:00 PM (tentative)\n\n\n\n\nLecture Schedule\n\n\nMondays and Thursdays, 8:30 AM - 9:50 AM\n\n\nHSD A240\n\n\nTextbooks\n\n\nRequired:   Algorithms (Fourth Edition) Robert Sedgewick and Kevin Wayne Addison-Wesley, 2011\n\n\nI-clickers\n\n\nStudents are required to bring their iClickers to each lecture; the clickers will not be used in the labs.\n\n\nGrading\n\n\n\n\n\n\n\n\nTask\n\n\nWeight\n\n\n\n\n\n\n\n\n\n\nParticipation\n\n\n5%\n\n\n\n\n\n\nAssignments\n\n\n25%\n\n\n\n\n\n\nMidterm\n\n\n20%\n\n\n\n\n\n\nFinal\n\n\n50%\n\n\n\n\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\nAssignment #\n\n\nWeight\n\n\nDue Date\n\n\n\n\n\n\n\n\n\n\n1\n\n\n5%\n\n\nJanuary 23\n\n\n\n\n\n\n2\n\n\n5%\n\n\nFebruary 5\n\n\n\n\n\n\n3\n\n\n5%\n\n\nMarch 18\n\n\n\n\n\n\n4\n\n\n5%\n\n\nApril 4\n\n\n\n\n\n\n5\n\n\n5%\n\n\nMarch 25", 
            "title": "Home"
        }, 
        {
            "location": "/#csc-226", 
            "text": "", 
            "title": "CSC 226"
        }, 
        {
            "location": "/#course-website", 
            "text": "", 
            "title": "Course Website"
        }, 
        {
            "location": "/#textbook-website", 
            "text": "", 
            "title": "Textbook Website"
        }, 
        {
            "location": "/#instructor", 
            "text": "Name : Frank Ruskey   Email :  ruskey@uvic.ca  Office : ECS 564   Office Hours : Mondays and Thursdays, 1:30 PM - 3:00 PM (tentative)", 
            "title": "Instructor"
        }, 
        {
            "location": "/#lecture-schedule", 
            "text": "Mondays and Thursdays, 8:30 AM - 9:50 AM  HSD A240", 
            "title": "Lecture Schedule"
        }, 
        {
            "location": "/#textbooks", 
            "text": "Required:   Algorithms (Fourth Edition) Robert Sedgewick and Kevin Wayne Addison-Wesley, 2011", 
            "title": "Textbooks"
        }, 
        {
            "location": "/#i-clickers", 
            "text": "Students are required to bring their iClickers to each lecture; the clickers will not be used in the labs.", 
            "title": "I-clickers"
        }, 
        {
            "location": "/#grading", 
            "text": "Task  Weight      Participation  5%    Assignments  25%    Midterm  20%    Final  50%", 
            "title": "Grading"
        }, 
        {
            "location": "/#assignments", 
            "text": "Assignment #  Weight  Due Date      1  5%  January 23    2  5%  February 5    3  5%  March 18    4  5%  April 4    5  5%  March 25", 
            "title": "Assignments"
        }, 
        {
            "location": "/2016-01-04/", 
            "text": "Lecture 1 - Notes\n\n\nJanuary 4, 2016\n\n\nTrees\n\n\nTopological trees\n\n\n\n\nFree trees\n\n\nRooted trees\n\n\nOrdered trees\n\n\nBinary trees\n\n\n\n\nFree Trees\n\n\n\n\nA free tree is the most general kind of tree.\n\n\n\n\ndefinition\n: A \nfree tree\n is an acyclic connected graph.\n\n\n\n\nAcyclic\n: No cycles\n\n\nConnected\n: There is a path between any two vertices\n\n\n\n\n\n\nA \nfree tree\n with $n$ nodes always has $e = n-1$ edges.\n\n\nExample\n\n\nHow many trees are there with $n = 3$ vertices?\n\n\nSolution\n\n\nOne. See above.\n\n\nRooted Trees\n\n\ndefinition\n: A \nrooted tree\n is a tree in which some node is distinguished as the root.\n\n\n\n\nExample\n\n\nHow many trees are there with $n = 4$ vertices?\n\n\nSolution\n\n\nFour. See above.\n\n\nOrdered Trees\n\n\ndefinition\n: An \nordered tree\n is a rooted tree in which the subtrees are ordered recursively.\n\n\nThe tree is ordered \"horizontally\" (because that's how levels work).\n\n\n\n\nBinary Trees\n\n\ndefinition\n: A \nBinary Tree\n is either empty or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint binary trees.\n\n\n\n\nExample\n\n\nHow many trees are there with $n = 3$ vertices?\n\n\nSolution\n\n\nFive. See above.\n\n\nExtended Binary Trees\n\n\ndefinition\n: An \nExtended Binary Tree\n is either a leaf node or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint extended binary trees.\n\n\n\n\n\n\nA binary tree where each node has two children called leaves\n\n\nA binary tree in which special nodes are added wherever a null subtree was present in the original tree so that each node in the original tree will always have 2 children (excluding an empty tree)\n\n\n\n\nAn \nExtended Binary Tree\n with $n$ internal nodes has $l = n + 1$ leaves.\n\n\nApplications\n\n\n\n\nBinary Search Trees - Binary Tree\n\n\nDecision Trees - Extended Binary Tree\n\n\n\n\nRepresentations\n\n\nBinary Trees\n\n\nEach node represented with a data value and left and right child nodes.\n\n\n\n\nclass Node {\n    Object data;\n    Node leftChild;\n    Node rightChild;\n}\n\n\n\n\nTree Traversal\n\n\nPreorder\n\n\n\n\nIn-order\n\n\n\n\nPostorder\n\n\n\n\nConverting a Ordered Forest into a Binary Tree\n\n\n\n\n\n\nUse the root of the ordered tree as the root of the binary tree\n\n\nThe leftmost node in the ordered tree becomes the left child of the parent node\n\n\nContinue finding children of the parent node insert it as the right subtree of leftmost child\n\n\nRepeat this process for all of the nodes\n\n\nNodes that have children in the ordered tree representation will have a left child in the binary tree representation\n\n\nIf a node has a right child in the binary tree representation it has siblings in the ordered tree representation", 
            "title": "2016 01 04"
        }, 
        {
            "location": "/2016-01-04/#lecture-1-notes", 
            "text": "", 
            "title": "Lecture 1 - Notes"
        }, 
        {
            "location": "/2016-01-04/#january-4-2016", 
            "text": "", 
            "title": "January 4, 2016"
        }, 
        {
            "location": "/2016-01-04/#trees", 
            "text": "Topological trees   Free trees  Rooted trees  Ordered trees  Binary trees", 
            "title": "Trees"
        }, 
        {
            "location": "/2016-01-04/#free-trees", 
            "text": "A free tree is the most general kind of tree.   definition : A  free tree  is an acyclic connected graph.   Acyclic : No cycles  Connected : There is a path between any two vertices    A  free tree  with $n$ nodes always has $e = n-1$ edges.", 
            "title": "Free Trees"
        }, 
        {
            "location": "/2016-01-04/#example", 
            "text": "How many trees are there with $n = 3$ vertices?", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-04/#solution", 
            "text": "One. See above.", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-01-04/#rooted-trees", 
            "text": "definition : A  rooted tree  is a tree in which some node is distinguished as the root.", 
            "title": "Rooted Trees"
        }, 
        {
            "location": "/2016-01-04/#example_1", 
            "text": "How many trees are there with $n = 4$ vertices?", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-04/#solution_1", 
            "text": "Four. See above.", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-01-04/#ordered-trees", 
            "text": "definition : An  ordered tree  is a rooted tree in which the subtrees are ordered recursively.  The tree is ordered \"horizontally\" (because that's how levels work).", 
            "title": "Ordered Trees"
        }, 
        {
            "location": "/2016-01-04/#binary-trees", 
            "text": "definition : A  Binary Tree  is either empty or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint binary trees.", 
            "title": "Binary Trees"
        }, 
        {
            "location": "/2016-01-04/#example_2", 
            "text": "How many trees are there with $n = 3$ vertices?", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-04/#solution_2", 
            "text": "Five. See above.", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-01-04/#extended-binary-trees", 
            "text": "definition : An  Extended Binary Tree  is either a leaf node or consists of a root, a left subtree $L$ and a right subtree $R$ both of which are disjoint extended binary trees.    A binary tree where each node has two children called leaves  A binary tree in which special nodes are added wherever a null subtree was present in the original tree so that each node in the original tree will always have 2 children (excluding an empty tree)   An  Extended Binary Tree  with $n$ internal nodes has $l = n + 1$ leaves.", 
            "title": "Extended Binary Trees"
        }, 
        {
            "location": "/2016-01-04/#applications", 
            "text": "Binary Search Trees - Binary Tree  Decision Trees - Extended Binary Tree", 
            "title": "Applications"
        }, 
        {
            "location": "/2016-01-04/#representations", 
            "text": "", 
            "title": "Representations"
        }, 
        {
            "location": "/2016-01-04/#binary-trees_1", 
            "text": "Each node represented with a data value and left and right child nodes.   class Node {\n    Object data;\n    Node leftChild;\n    Node rightChild;\n}", 
            "title": "Binary Trees"
        }, 
        {
            "location": "/2016-01-04/#tree-traversal", 
            "text": "", 
            "title": "Tree Traversal"
        }, 
        {
            "location": "/2016-01-04/#preorder", 
            "text": "", 
            "title": "Preorder"
        }, 
        {
            "location": "/2016-01-04/#in-order", 
            "text": "", 
            "title": "In-order"
        }, 
        {
            "location": "/2016-01-04/#postorder", 
            "text": "", 
            "title": "Postorder"
        }, 
        {
            "location": "/2016-01-04/#converting-a-ordered-forest-into-a-binary-tree", 
            "text": "Use the root of the ordered tree as the root of the binary tree  The leftmost node in the ordered tree becomes the left child of the parent node  Continue finding children of the parent node insert it as the right subtree of leftmost child  Repeat this process for all of the nodes  Nodes that have children in the ordered tree representation will have a left child in the binary tree representation  If a node has a right child in the binary tree representation it has siblings in the ordered tree representation", 
            "title": "Converting a Ordered Forest into a Binary Tree"
        }, 
        {
            "location": "/2016-01-07/", 
            "text": "Lecture 2 - Notes\n\n\nJanuary 7, 2016\n\n\nEncoding Trees\n\n\nMark internal nodes with ones and leaves with zeros. We then do a preorder traversal. This gives us a sequence, e.g.,\n\n\n\n\n\n    11100011000\n\n\n\n\n\nThis \ntree sequence\n let's us create a well formed parenthesis string.\n\n\n\n\n\n    \\underset{1}(\\underset{1}(\\underset{1}(\\underset{0})\\underset{0})\\underset{0})\\underset{1}(\\underset{1}( \\underset{0}) \\underset{0})\n\n\n\n\n\nThis parenthesis string is \nunique\n to that tree.\n\n\nUnion Find\n\n\nGiven a set of $N$ object we would like to,\n\n\n\n\nConnect two objects\n\n\nTest if theirs a path between two objects\n\n\n\n\nTo find out if a \nstatic\n graph is connected you could use DFS or BFS which is $O(|V| + |E|)$.\n\n\nIn this \ndynamic\n environment we are adding edges to the graph. We assume \"is connected to\" to be an equivalence relation. We will therefor use sets to encapsulate components, when creating edges we will check which set each node is in then join the two sets.\n\n\nclass UF\n{\n    UF (int n)\n\n    void union(int p,  int q)\n\n    int find(int p)\n\n    boolean connected(int p, int q)\n}\n\n\n\n\nQuick Find\n\n\nData structure\n\n\n\n\nInteger array \nid[]\n of length \nN\n\n\nInterpretation \nid[p]\n is the id of the component containing \np\n\n\n\n\nExample\n\n\n          0 1 2 3 4 5 6 7 8 9\n    id = [0,1,1,8,8,0,0,1,8,8]\n\n\n\n\nSo 0, 5 and 6 are connected, etc.\n\n\n\n\nfind(p)\n: Lookup \np\n by index\n\n\nconnected(p,q)\n: Do \np\n and \nq\n have the same id?\n\n\nunion(p,q)\n: Change all entries were id is \nid[p]\n to \nid[q]\n\n\n\n\nQuick Union\n\n\nData Structure\n\n\n\n\nInteger array \nid[]\n of length \nN\n\n\nInterpretation \nid[i]\n is the parent of \ni\n\n\nRoot of \ni\n is \nid[id[...id[i]...]]\n\n\n\n\n          0 1 2 3 4 5 6 7 8 9\n    id = [0,1,9,4,9,6,6,7,8,9]\n\n\n\n\n\n\nfind(p)\n: What is the root of \np\n\n\nconnected(p,q)\n: Do \np\n and \nq\n have the same root?\n\n\nunion(p,q)\n: Set the id of \np\n's root to the id of \nq\n's root\n\n\n\n\nIssues\n\n\nBoth of the these operation are too expensive,\n\n\n\n\n\n\n\n\nAlgorithm\n\n\nintialize\n\n\nunion\n\n\nfind\n\n\nconnected\n\n\n\n\n\n\n\n\n\n\nQuick Find\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(1)$\n\n\n$O(1)$\n\n\n\n\n\n\nQuick Union\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n\n\n\n\n\n\nQuick Find\n\n\n\n\nUnions are expensive\n\n\nTrees are flat but it's expensive to eep them flat\n\n\n\n\nQuick Union\n\n\n\n\nTrees can get very tall\n\n\nFind/connect is expensive\n\n\n\n\nWeighted Quick Union\n\n\n\n\nModify Quick Union to avoid tall trees\n\n\nKeep track of the size of each tree\n\n\nBalance by linking smaller tree to root of larger tree\n\n\n\n\nData Structure\n\n\nSame as Quick Union but maintain an extra array \nsz[i]\n that counts the number of objects rooted at \ni\n.\n\n\n\n\nfind(p)\n/\nconnected(p,q)\n: Same as Quick Union\n\n\nUnion(p,q)\n: Link the smaller tree to the larger tree, update \nsz[]\n\n\n\n\nEfficiency\n\n\n\n\n\n\n\n\nAlgorithm\n\n\ninitialize\n\n\nunion\n\n\nfind\n\n\nconnected\n\n\n\n\n\n\n\n\n\n\nQuick Find\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(1)$\n\n\n$O(1)$\n\n\n\n\n\n\nQuick Union\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n$O(N)$\n\n\n\n\n\n\nWeighted Quick Union\n\n\n$O(N)$\n\n\n$O(\\lg{N})$\n\n\n$O(\\lg{N})$\n\n\n$O(\\lg{N})$", 
            "title": "2016 01 07"
        }, 
        {
            "location": "/2016-01-07/#lecture-2-notes", 
            "text": "", 
            "title": "Lecture 2 - Notes"
        }, 
        {
            "location": "/2016-01-07/#january-7-2016", 
            "text": "", 
            "title": "January 7, 2016"
        }, 
        {
            "location": "/2016-01-07/#encoding-trees", 
            "text": "Mark internal nodes with ones and leaves with zeros. We then do a preorder traversal. This gives us a sequence, e.g.,   \n    11100011000   This  tree sequence  let's us create a well formed parenthesis string.   \n    \\underset{1}(\\underset{1}(\\underset{1}(\\underset{0})\\underset{0})\\underset{0})\\underset{1}(\\underset{1}( \\underset{0}) \\underset{0})   This parenthesis string is  unique  to that tree.", 
            "title": "Encoding Trees"
        }, 
        {
            "location": "/2016-01-07/#union-find", 
            "text": "Given a set of $N$ object we would like to,   Connect two objects  Test if theirs a path between two objects   To find out if a  static  graph is connected you could use DFS or BFS which is $O(|V| + |E|)$.  In this  dynamic  environment we are adding edges to the graph. We assume \"is connected to\" to be an equivalence relation. We will therefor use sets to encapsulate components, when creating edges we will check which set each node is in then join the two sets.  class UF\n{\n    UF (int n)\n\n    void union(int p,  int q)\n\n    int find(int p)\n\n    boolean connected(int p, int q)\n}", 
            "title": "Union Find"
        }, 
        {
            "location": "/2016-01-07/#quick-find", 
            "text": "", 
            "title": "Quick Find"
        }, 
        {
            "location": "/2016-01-07/#data-structure", 
            "text": "Integer array  id[]  of length  N  Interpretation  id[p]  is the id of the component containing  p", 
            "title": "Data structure"
        }, 
        {
            "location": "/2016-01-07/#example", 
            "text": "0 1 2 3 4 5 6 7 8 9\n    id = [0,1,1,8,8,0,0,1,8,8]  So 0, 5 and 6 are connected, etc.   find(p) : Lookup  p  by index  connected(p,q) : Do  p  and  q  have the same id?  union(p,q) : Change all entries were id is  id[p]  to  id[q]", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-07/#quick-union", 
            "text": "", 
            "title": "Quick Union"
        }, 
        {
            "location": "/2016-01-07/#data-structure_1", 
            "text": "Integer array  id[]  of length  N  Interpretation  id[i]  is the parent of  i  Root of  i  is  id[id[...id[i]...]]             0 1 2 3 4 5 6 7 8 9\n    id = [0,1,9,4,9,6,6,7,8,9]   find(p) : What is the root of  p  connected(p,q) : Do  p  and  q  have the same root?  union(p,q) : Set the id of  p 's root to the id of  q 's root", 
            "title": "Data Structure"
        }, 
        {
            "location": "/2016-01-07/#issues", 
            "text": "Both of the these operation are too expensive,     Algorithm  intialize  union  find  connected      Quick Find  $O(N)$  $O(N)$  $O(1)$  $O(1)$    Quick Union  $O(N)$  $O(N)$  $O(N)$  $O(N)$", 
            "title": "Issues"
        }, 
        {
            "location": "/2016-01-07/#quick-find_1", 
            "text": "Unions are expensive  Trees are flat but it's expensive to eep them flat", 
            "title": "Quick Find"
        }, 
        {
            "location": "/2016-01-07/#quick-union_1", 
            "text": "Trees can get very tall  Find/connect is expensive", 
            "title": "Quick Union"
        }, 
        {
            "location": "/2016-01-07/#weighted-quick-union", 
            "text": "Modify Quick Union to avoid tall trees  Keep track of the size of each tree  Balance by linking smaller tree to root of larger tree", 
            "title": "Weighted Quick Union"
        }, 
        {
            "location": "/2016-01-07/#data-structure_2", 
            "text": "Same as Quick Union but maintain an extra array  sz[i]  that counts the number of objects rooted at  i .   find(p) / connected(p,q) : Same as Quick Union  Union(p,q) : Link the smaller tree to the larger tree, update  sz[]", 
            "title": "Data Structure"
        }, 
        {
            "location": "/2016-01-07/#efficiency", 
            "text": "Algorithm  initialize  union  find  connected      Quick Find  $O(N)$  $O(N)$  $O(1)$  $O(1)$    Quick Union  $O(N)$  $O(N)$  $O(N)$  $O(N)$    Weighted Quick Union  $O(N)$  $O(\\lg{N})$  $O(\\lg{N})$  $O(\\lg{N})$", 
            "title": "Efficiency"
        }, 
        {
            "location": "/2016-01-11/", 
            "text": "Lecture 3 - Notes\n\n\nJanuary 11, 2016\n\n\nWeighted Quick Union --- Continued\n\n\nUnion\n\n\nProposition\n, The depth of any node is $\\le \\lg N$.\n\n\nProof:\n\n\nThe depth goes up (by 1) only on a union with $x$ where $x$ is in the smaller tree,\n\n\n\n\nthe size of the tree containing $x$ is at least twice as large on such a union\n\n\nthe size of a tree can double at most $\\lg N$ times\n\n\n\n\nUsing \nrank\n instead of node count to track the size of the trees can reduce the space complexity since the maximum bit length for the rank is $\\le \\lg(\\lg(N))$\n\n\nCompression\n\n\nWe make nodes along the find path point to the root.\n\n\nTo do this \nwith two passes\n we can perform a second loop setting every node to the root.\n\n\nTo do this \nwith one path\n this make every other node in the path point to it's grandparent.\n\n\npublic int find(int i)\n{\n   while (i != id[i])\n   {\n      id[i] = id[id[i]]; //\n-- Set the Grandparent\n      i = id[i]; \n   }\n   return i;\n}\n\n\n\n\nComparison Based Sorting\n\n\nIn \nComparison Based Sorting\n like,\n\n\n\n\nMergesort\n\n\nQuicksort\n\n\nHeapsort\n\n\n\n\nLet's say we are sorting something \nsort([a,b,c])\n,\n\n\n\n\nThis comparison tree has 6 leaves. In general it has to be $\\ge N!$ (because that's how many possible combinations there are).\n\n\nThe height is the worst case number of comparisons, in this case 3. What is the minimum height $h$ of an extended binary tree with $n$ leaves?\n\n\n\n\n\\begin{align}\n    n &\\le 2^h \\newline\n    \\lceil \\lg n \\rceil &\\le h\n\\end{align}\n\n\n\n\nTherefore the height for sorting is $\\ge \\lceil \\lg{N!} \\rceil$. We can bound $N!$ with,\n\n\n\n\n\\begin{align}\n    \\left( \\frac{n}{2} \\right) ^ \\frac{n}{2} \\le N! \\le N^N\n\\end{align}\n\n\n\n\nand by taking the log,\n\n\n\n\n\\begin{align}\n    \\frac{n}{2} \\lg \\left( \\frac{n}{2} \\right) \\le \\lg{N!} \\le N \\lg {N}\n\\end{align}\n\n\n\n\nSo comparison based sorting requires $\\Omega (N \\lg N)$ comparisons.", 
            "title": "2016 01 11"
        }, 
        {
            "location": "/2016-01-11/#lecture-3-notes", 
            "text": "", 
            "title": "Lecture 3 - Notes"
        }, 
        {
            "location": "/2016-01-11/#january-11-2016", 
            "text": "", 
            "title": "January 11, 2016"
        }, 
        {
            "location": "/2016-01-11/#weighted-quick-union-continued", 
            "text": "", 
            "title": "Weighted Quick Union --- Continued"
        }, 
        {
            "location": "/2016-01-11/#union", 
            "text": "Proposition , The depth of any node is $\\le \\lg N$.  Proof:  The depth goes up (by 1) only on a union with $x$ where $x$ is in the smaller tree,   the size of the tree containing $x$ is at least twice as large on such a union  the size of a tree can double at most $\\lg N$ times   Using  rank  instead of node count to track the size of the trees can reduce the space complexity since the maximum bit length for the rank is $\\le \\lg(\\lg(N))$", 
            "title": "Union"
        }, 
        {
            "location": "/2016-01-11/#compression", 
            "text": "We make nodes along the find path point to the root.  To do this  with two passes  we can perform a second loop setting every node to the root.  To do this  with one path  this make every other node in the path point to it's grandparent.  public int find(int i)\n{\n   while (i != id[i])\n   {\n      id[i] = id[id[i]]; // -- Set the Grandparent\n      i = id[i]; \n   }\n   return i;\n}", 
            "title": "Compression"
        }, 
        {
            "location": "/2016-01-11/#comparison-based-sorting", 
            "text": "In  Comparison Based Sorting  like,   Mergesort  Quicksort  Heapsort   Let's say we are sorting something  sort([a,b,c]) ,   This comparison tree has 6 leaves. In general it has to be $\\ge N!$ (because that's how many possible combinations there are).  The height is the worst case number of comparisons, in this case 3. What is the minimum height $h$ of an extended binary tree with $n$ leaves?   \\begin{align}\n    n &\\le 2^h \\newline\n    \\lceil \\lg n \\rceil &\\le h\n\\end{align}   Therefore the height for sorting is $\\ge \\lceil \\lg{N!} \\rceil$. We can bound $N!$ with,   \\begin{align}\n    \\left( \\frac{n}{2} \\right) ^ \\frac{n}{2} \\le N! \\le N^N\n\\end{align}   and by taking the log,   \\begin{align}\n    \\frac{n}{2} \\lg \\left( \\frac{n}{2} \\right) \\le \\lg{N!} \\le N \\lg {N}\n\\end{align}   So comparison based sorting requires $\\Omega (N \\lg N)$ comparisons.", 
            "title": "Comparison Based Sorting"
        }, 
        {
            "location": "/2016-01-14/", 
            "text": "Lecture 4 - Notes\n\n\nJanuary 14, 2016\n  \n\n\nComparison Based Lower Bounds\n\n\nIf we are solving a problem using only comparisons and there are $n$ possible outcomes, then in the worst case $\\lceil \\lg{n} \\rceil$ comparisons are required.\n\n\nExample\n\n\nSuppose we have an array of $n$ sorted elements and we want to find some element $x$.\n\n\nWe could use binary search which will give us $O(\\lg n)$. Instead we could use interpolation search $O\\left(\\lg{\\left(\\lg{n}\\right)}\\right)$.\n\n\nSorting\n\n\nLet say we're sorting again,\n\n\n\n\nA sorting algorithm can be viewed as transforming a totally unordered set into a totally ordered set. Below we have converter the sorting diagram into a graph of partial order sets.\n\n\n\n\nPartial Order Sets\n\n\ndefinition\n: A binary relation ($\\le$) on a set $S$ is a \npartial order\n if,\n\n\n\n\n$a \\le a$ for all $a \\in S$ (reflexive)\n\n\n$a \\le b$ and $b \\le a$ implies $a = b$ (anti-symmetric)\n\n\n$a \\le b$ and $b \\le c$ implies $a \\le c$ (transitive)\n\n\n\n\nA partially ordered set is sometimes called a \nposet\n.\n\n\nSome other variants of this ordering are,\n\n\n\n\n$\\le$ Weak Partial Order\n\n\n$\\lt$ Strick Partial Order\n\n\n$\\equiv$ Equivalence Relations\n\n\n\n\nHasse Diagram\n\n\ndefinition\n: A \nHasse Diagram\n of a partially ordered set (poset) $S$ is a graph $G = (S,E)$ where $(a,c) \\in E$ if and only if $a \\lt c$ and there is no $b$ such that $a \\lt b \\lt c$\n\n\nThese posets can be combined into a \nHasse diagram\n. Below are the Hasse diagrams for sorts of size 3 and 4.", 
            "title": "2016 01 14"
        }, 
        {
            "location": "/2016-01-14/#lecture-4-notes", 
            "text": "January 14, 2016", 
            "title": "Lecture 4 - Notes"
        }, 
        {
            "location": "/2016-01-14/#comparison-based-lower-bounds", 
            "text": "If we are solving a problem using only comparisons and there are $n$ possible outcomes, then in the worst case $\\lceil \\lg{n} \\rceil$ comparisons are required.", 
            "title": "Comparison Based Lower Bounds"
        }, 
        {
            "location": "/2016-01-14/#example", 
            "text": "Suppose we have an array of $n$ sorted elements and we want to find some element $x$.  We could use binary search which will give us $O(\\lg n)$. Instead we could use interpolation search $O\\left(\\lg{\\left(\\lg{n}\\right)}\\right)$.", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-14/#sorting", 
            "text": "Let say we're sorting again,   A sorting algorithm can be viewed as transforming a totally unordered set into a totally ordered set. Below we have converter the sorting diagram into a graph of partial order sets.", 
            "title": "Sorting"
        }, 
        {
            "location": "/2016-01-14/#partial-order-sets", 
            "text": "definition : A binary relation ($\\le$) on a set $S$ is a  partial order  if,   $a \\le a$ for all $a \\in S$ (reflexive)  $a \\le b$ and $b \\le a$ implies $a = b$ (anti-symmetric)  $a \\le b$ and $b \\le c$ implies $a \\le c$ (transitive)   A partially ordered set is sometimes called a  poset .  Some other variants of this ordering are,   $\\le$ Weak Partial Order  $\\lt$ Strick Partial Order  $\\equiv$ Equivalence Relations", 
            "title": "Partial Order Sets"
        }, 
        {
            "location": "/2016-01-14/#hasse-diagram", 
            "text": "definition : A  Hasse Diagram  of a partially ordered set (poset) $S$ is a graph $G = (S,E)$ where $(a,c) \\in E$ if and only if $a \\lt c$ and there is no $b$ such that $a \\lt b \\lt c$  These posets can be combined into a  Hasse diagram . Below are the Hasse diagrams for sorts of size 3 and 4.", 
            "title": "Hasse Diagram"
        }, 
        {
            "location": "/2016-01-18/", 
            "text": "Lecture 5 - Notes\n\n\nJanuary 18, 2016\n  \n\n\nToday\n\n\n\n\nFinish comparison based sorting\n\n\n2-3 and Red-Black Trees\n\n\n\n\nComparison Based Bounds\n\n\n\n\n\n\n\n\nProblem\n\n\nSize\n\n\nLower Bound\n\n\nUpper Bound\n\n\nReason\n\n\n\n\n\n\n\n\n\n\nmax\n\n\nof $n$\n\n\n$O(n-1)$\n\n\n$O(n-1)$\n\n\nSee \ngraph theory proof\n\n\n\n\n\n\nmerge\n\n\n$n+n$\n\n\n$O(2n-1)$\n\n\n$O(2n-1)$\n\n\nSee \nadversarial argument proof\n\n\n\n\n\n\nsearch on ordered table\n\n\n$n$\n\n\n$O(\\lg n)$\n\n\n$\\lceil \\lg n \\rceil$\n\n\nInformation Theory\n\n\n\n\n\n\nmax \n min\n\n\nof $n$\n\n\n$\\lceil \\frac{3}{2}n -2 \\rceil$\n\n\n$\\lceil \\frac{3}{n} -2 \\rceil$\n\n\nTricky adversarial argument\n\n\n\n\n\n\nmax \n next\n\n\nof $n$\n\n\n$n + \\lceil \\lg n \\rceil - 1$\n\n\n$n + \\lceil \\lg n \\rceil - 1$\n\n\nTricky adversarial argument\n\n\n\n\n\n\nsorting\n\n\n$n$\n\n\n$O(n \\ log n)$\n\n\n$\\lceil \\lg n! \\rceil$\n\n\nInformation theory\n\n\n\n\n\n\n\n\nNote:\n I know that $O(2n-1) = O(n)$ but Ruskey insists on \"more accurate numbers\". So I've added the big-o's even though they aren't strictly necessary.\n\n\nMax\n\n\nTheorem\n: $n - 1$ is the best upper bound for finding the maximum in an unordered array.\n\n\nProof\n: Make a graph $G = (V,E)$,\n\n\n\n\n\n    V = \\text{ vertices } = \\{a_1, a_2, ..., a_n \\}\n\n\n\n\n\nEach time a comparison is made say $a_i \\lt a_j$ add the edge $(i,j)$. If the algorithm is correct, then at the end $G$ must be connected. For $G$ to be connected it must have at least $\\left|E\\right| \\ge n - 1$ edges.\n\n\nMerge\n\n\nTheorem\n: $2n - 1$ is the best upper bound for the merge operation.\n\n\nProof\n: Suppose the input is ordered so that,\n\n\n\n\n\n    a_1 \\lt b_1 \\lt \\underbrace{a_2 \\lt b_2}_\\text{not made} \\lt ... \\lt a_n \\lt b_n\n\n\n\n\n\nIf some comparison, either $a_i \\lt b_i$ or $b_i \\lt a_{i+1}$ is not made, then the algorithm will fail. This is called an \nadversarial argument\n.\n\n\nMax \n Min\n\n\nIf we use a tree to model the comparisons, we have $\\frac{n}{2}$ comparisons on the first row. Since an extended binary tree has $N - 1$ internal nodes (where $N$ is the number of leaves), and our comparison tree has $\\frac{n}{2}$ leaves\n\n\n\n\n\\begin{align}\n    \\text{Comparisons} &= \\frac{n}{2} + 2 \\left( \\frac{n}{2} - 1 \\right) \\newline\n    &= \\frac{3}{2}n -2\n\\end{align}\n\n\n\n\nMax \n Next Max\n\n\nIf we use a tree like before, the next maxes will all be those that lost to the first max. Since we have one on each level we have another \"sub\" comparison set.\n\n\nBalanced Search Trees\n\n\nSlides\n\n\n2-3 Trees\n\n\ndefinition\n: A \n2-3 Tree\n is a search tree which allows,\n\n\n\n\n2-node\n: one key, two children \nor\n\n\n3-node\n: two keys, three children\n\n\n\n\nand we maintain,\n\n\n\n\nSymmetric order\n: Inorder traversal yields keys in ascending order\n\n\nPerfect balance\n: Every path from root to null link has same length\n\n\n\n\nSearch\n\n\nSearch work more-or-less as it would on a binary search tree working it's way down from the root.\n\n\nInsertion\n\n\nIf we insert into a 2-node we can just make it a 3-node. If we insert into a 3-node,\n\n\n\n\nAdd new key to 3-node to create temporary 4-node\n\n\nMove middle key in 4-node into parent\n\n\nRepeat up the tree, as necessary\n\n\nIf you reach the root and it's a 4-node, split it into three 2-nodes\n\n\n\n\nBecause the rest of the tree isn't affected, splitting a 4-node is a \nlocal transformation\n and requires \nconstant time\n.\n\n\nPerfect Balance\n\n\nPerfect balance means that every path from the root to a leaf is the same length. The height is therefore,\n\n\n\n\n\n\n\n\n\n\nTree Height\n\n\nReason\n\n\n\n\n\n\n\n\n\n\nWorst Case\n\n\n$\\lg N$\n\n\nAll 2-nodes\n\n\n\n\n\n\nBest Case\n\n\n$\\log_3 N$\n\n\nAll 3-nodes\n\n\n\n\n\n\n\n\nIn practice this means between 12 and 20 for a million nodes and between 18 and 30 for a billion nodes. The bottom line is 2-3 trees provide \nguaranteed logarithmic performance\n.\n\n\nImplementation\n\n\nDirectly implementing a 2-3 tree is complicated, because,\n\n\n\n\nMaintaining multiple node types is cumbersome\n\n\nNeed multiple compares to move down tree\n\n\nNeed to move back up the tree to split 4-nodes\n\n\nLarge number of cases for splitting\n\n\n\n\nfor example,\n\n\npublic void put(Key key, Value val)\n{\n  Node x = root;\n  while (x.getTheCorrectChild(key) != null)\n  {\n    x = x.getTheCorrectChildKey();\n    if (x.is4Node()) x.split();\n  }\n  if (x.is2Node()) x.make3Node(key, val);\n  else if (x.is3Node()) x.make4Node(key, val);\n}", 
            "title": "2016 01 18"
        }, 
        {
            "location": "/2016-01-18/#lecture-5-notes", 
            "text": "January 18, 2016", 
            "title": "Lecture 5 - Notes"
        }, 
        {
            "location": "/2016-01-18/#today", 
            "text": "Finish comparison based sorting  2-3 and Red-Black Trees", 
            "title": "Today"
        }, 
        {
            "location": "/2016-01-18/#comparison-based-bounds", 
            "text": "Problem  Size  Lower Bound  Upper Bound  Reason      max  of $n$  $O(n-1)$  $O(n-1)$  See  graph theory proof    merge  $n+n$  $O(2n-1)$  $O(2n-1)$  See  adversarial argument proof    search on ordered table  $n$  $O(\\lg n)$  $\\lceil \\lg n \\rceil$  Information Theory    max   min  of $n$  $\\lceil \\frac{3}{2}n -2 \\rceil$  $\\lceil \\frac{3}{n} -2 \\rceil$  Tricky adversarial argument    max   next  of $n$  $n + \\lceil \\lg n \\rceil - 1$  $n + \\lceil \\lg n \\rceil - 1$  Tricky adversarial argument    sorting  $n$  $O(n \\ log n)$  $\\lceil \\lg n! \\rceil$  Information theory     Note:  I know that $O(2n-1) = O(n)$ but Ruskey insists on \"more accurate numbers\". So I've added the big-o's even though they aren't strictly necessary.", 
            "title": "Comparison Based Bounds"
        }, 
        {
            "location": "/2016-01-18/#max", 
            "text": "Theorem : $n - 1$ is the best upper bound for finding the maximum in an unordered array.  Proof : Make a graph $G = (V,E)$,   \n    V = \\text{ vertices } = \\{a_1, a_2, ..., a_n \\}   Each time a comparison is made say $a_i \\lt a_j$ add the edge $(i,j)$. If the algorithm is correct, then at the end $G$ must be connected. For $G$ to be connected it must have at least $\\left|E\\right| \\ge n - 1$ edges.", 
            "title": "Max"
        }, 
        {
            "location": "/2016-01-18/#merge", 
            "text": "Theorem : $2n - 1$ is the best upper bound for the merge operation.  Proof : Suppose the input is ordered so that,   \n    a_1 \\lt b_1 \\lt \\underbrace{a_2 \\lt b_2}_\\text{not made} \\lt ... \\lt a_n \\lt b_n   If some comparison, either $a_i \\lt b_i$ or $b_i \\lt a_{i+1}$ is not made, then the algorithm will fail. This is called an  adversarial argument .", 
            "title": "Merge"
        }, 
        {
            "location": "/2016-01-18/#max-min", 
            "text": "If we use a tree to model the comparisons, we have $\\frac{n}{2}$ comparisons on the first row. Since an extended binary tree has $N - 1$ internal nodes (where $N$ is the number of leaves), and our comparison tree has $\\frac{n}{2}$ leaves   \\begin{align}\n    \\text{Comparisons} &= \\frac{n}{2} + 2 \\left( \\frac{n}{2} - 1 \\right) \\newline\n    &= \\frac{3}{2}n -2\n\\end{align}", 
            "title": "Max &amp; Min"
        }, 
        {
            "location": "/2016-01-18/#max-next-max", 
            "text": "If we use a tree like before, the next maxes will all be those that lost to the first max. Since we have one on each level we have another \"sub\" comparison set.", 
            "title": "Max &amp; Next Max"
        }, 
        {
            "location": "/2016-01-18/#balanced-search-trees", 
            "text": "", 
            "title": "Balanced Search Trees"
        }, 
        {
            "location": "/2016-01-18/#slides", 
            "text": "", 
            "title": "Slides"
        }, 
        {
            "location": "/2016-01-18/#2-3-trees", 
            "text": "definition : A  2-3 Tree  is a search tree which allows,   2-node : one key, two children  or  3-node : two keys, three children   and we maintain,   Symmetric order : Inorder traversal yields keys in ascending order  Perfect balance : Every path from root to null link has same length", 
            "title": "2-3 Trees"
        }, 
        {
            "location": "/2016-01-18/#search", 
            "text": "Search work more-or-less as it would on a binary search tree working it's way down from the root.", 
            "title": "Search"
        }, 
        {
            "location": "/2016-01-18/#insertion", 
            "text": "If we insert into a 2-node we can just make it a 3-node. If we insert into a 3-node,   Add new key to 3-node to create temporary 4-node  Move middle key in 4-node into parent  Repeat up the tree, as necessary  If you reach the root and it's a 4-node, split it into three 2-nodes   Because the rest of the tree isn't affected, splitting a 4-node is a  local transformation  and requires  constant time .", 
            "title": "Insertion"
        }, 
        {
            "location": "/2016-01-18/#perfect-balance", 
            "text": "Perfect balance means that every path from the root to a leaf is the same length. The height is therefore,      Tree Height  Reason      Worst Case  $\\lg N$  All 2-nodes    Best Case  $\\log_3 N$  All 3-nodes     In practice this means between 12 and 20 for a million nodes and between 18 and 30 for a billion nodes. The bottom line is 2-3 trees provide  guaranteed logarithmic performance .", 
            "title": "Perfect Balance"
        }, 
        {
            "location": "/2016-01-18/#implementation", 
            "text": "Directly implementing a 2-3 tree is complicated, because,   Maintaining multiple node types is cumbersome  Need multiple compares to move down tree  Need to move back up the tree to split 4-nodes  Large number of cases for splitting   for example,  public void put(Key key, Value val)\n{\n  Node x = root;\n  while (x.getTheCorrectChild(key) != null)\n  {\n    x = x.getTheCorrectChildKey();\n    if (x.is4Node()) x.split();\n  }\n  if (x.is2Node()) x.make3Node(key, val);\n  else if (x.is3Node()) x.make4Node(key, val);\n}", 
            "title": "Implementation"
        }, 
        {
            "location": "/2016-01-21/", 
            "text": "Lecture 6 - Notes\n\n\nJanuary 21, 2016\n  \n\n\nBalance Search Trees - Contined\n\n\nRed-Black Trees\n\n\nA better way to represent a represent a 2-3 tree using a binary tree with one edge used as the \"glue\" edge to create a 3-node. We apply the arbitrary restriction the the red link are on the left.\n\n\ndefinition\n: A \nRed-Black Tree\n is a binary search tree where,\n\n\n\n\nNo node has two red links connected to it\n\n\nEvery path from root to null link has the same number of black links (perfect black balance)\n\n\nRed links lean left\n\n\n\n\nthis tree also has a one-to-one correspondence with a 2-3 tree. To map the correspondence the \nred\n links are used to \"join\" 3-nodes.\n\n\nSearch\n\n\nSearch is the same as a normal binary search tree but faster because of better balance.\n\n\nLeft Rotation\n\n\nTo bring a (temporarily) right leaning edge to the left, we need to do a left rotation,\n\n\n\n\nprivate Node rotateLeft(Node h)\n{\n   assert isRed(h.right);\n   Node x = h.right;\n   h.right = x.left;\n   x.left = h;\n   x.color = h.color;\n   h.color = RED;\n   return x;\n}\n\n\n\n\nRight Rotation\n\n\nTo bring a left leaning edge to the right (temporarily), we do a right rotation,\n\n\n\n\nprivate Node rotateRight(Node h)\n{\n   assert isRed(h.left);\n   Node x = h.left;\n   h.left = x.right;\n   x.right = h;\n   x.color = h.color;\n   h.color = RED;\n   return x;\n}\n\n\n\n\nColor Flip\n\n\nTo recolour to split a (temporary) 4-node,\n\n\nprivate void flipColors(Node h)\n{\n   assert !isRed(h);\n   assert isRed(h.left);\n   assert isRed(h.right);\n   h.color = RED;\n   h.left.color = BLACK;\n   h.right.color = BLACK;\n}\n\n\n\n\nInsertion\n\n\nInsert a node we navigate the Binary Search Tree and perform the insertion using a red edge (so we maintain perfect black balance). Then we move back up the tree fixing any issues we create.\n\n\n\n\nRight child red, left child black: rotate left.\n\n\nLeft child, left-left grandchild red: rotate right.\n\n\nBoth children red: flip colors.\n\n\n\n\nprivate Node put(Node h, Key key, Value val)\n{\n   if (h == null) return new Node(key, val, RED);\n   int cmp = key.compareTo(h.key);\n   if      (cmp  \n 0) h.left  = put(h.left,  key, val);\n   else if (cmp  \n 0) h.right = put(h.right, key, val);\n   else if (cmp == 0) h.val = val;\n\n    if (isRed(h.right) \n !isRed(h.left))     h = rotateLeft(h);\n    if (isRed(h.left)  \n isRed(h.left.left)) h = rotateRight(h);\n    if (isRed(h.left)  \n isRed(h.right))     flipColors(h);\n    return h; \n}\n\n\n\n\nBalance\n\n\nProperty\n: The height of the tree is $\\le 2 \\lg N$ in the worst case.", 
            "title": "2016 01 21"
        }, 
        {
            "location": "/2016-01-21/#lecture-6-notes", 
            "text": "January 21, 2016", 
            "title": "Lecture 6 - Notes"
        }, 
        {
            "location": "/2016-01-21/#balance-search-trees-contined", 
            "text": "", 
            "title": "Balance Search Trees - Contined"
        }, 
        {
            "location": "/2016-01-21/#red-black-trees", 
            "text": "A better way to represent a represent a 2-3 tree using a binary tree with one edge used as the \"glue\" edge to create a 3-node. We apply the arbitrary restriction the the red link are on the left.  definition : A  Red-Black Tree  is a binary search tree where,   No node has two red links connected to it  Every path from root to null link has the same number of black links (perfect black balance)  Red links lean left   this tree also has a one-to-one correspondence with a 2-3 tree. To map the correspondence the  red  links are used to \"join\" 3-nodes.", 
            "title": "Red-Black Trees"
        }, 
        {
            "location": "/2016-01-21/#search", 
            "text": "Search is the same as a normal binary search tree but faster because of better balance.", 
            "title": "Search"
        }, 
        {
            "location": "/2016-01-21/#left-rotation", 
            "text": "To bring a (temporarily) right leaning edge to the left, we need to do a left rotation,   private Node rotateLeft(Node h)\n{\n   assert isRed(h.right);\n   Node x = h.right;\n   h.right = x.left;\n   x.left = h;\n   x.color = h.color;\n   h.color = RED;\n   return x;\n}", 
            "title": "Left Rotation"
        }, 
        {
            "location": "/2016-01-21/#right-rotation", 
            "text": "To bring a left leaning edge to the right (temporarily), we do a right rotation,   private Node rotateRight(Node h)\n{\n   assert isRed(h.left);\n   Node x = h.left;\n   h.left = x.right;\n   x.right = h;\n   x.color = h.color;\n   h.color = RED;\n   return x;\n}", 
            "title": "Right Rotation"
        }, 
        {
            "location": "/2016-01-21/#color-flip", 
            "text": "To recolour to split a (temporary) 4-node,  private void flipColors(Node h)\n{\n   assert !isRed(h);\n   assert isRed(h.left);\n   assert isRed(h.right);\n   h.color = RED;\n   h.left.color = BLACK;\n   h.right.color = BLACK;\n}", 
            "title": "Color Flip"
        }, 
        {
            "location": "/2016-01-21/#insertion", 
            "text": "Insert a node we navigate the Binary Search Tree and perform the insertion using a red edge (so we maintain perfect black balance). Then we move back up the tree fixing any issues we create.   Right child red, left child black: rotate left.  Left child, left-left grandchild red: rotate right.  Both children red: flip colors.   private Node put(Node h, Key key, Value val)\n{\n   if (h == null) return new Node(key, val, RED);\n   int cmp = key.compareTo(h.key);\n   if      (cmp    0) h.left  = put(h.left,  key, val);\n   else if (cmp    0) h.right = put(h.right, key, val);\n   else if (cmp == 0) h.val = val;\n\n    if (isRed(h.right)   !isRed(h.left))     h = rotateLeft(h);\n    if (isRed(h.left)    isRed(h.left.left)) h = rotateRight(h);\n    if (isRed(h.left)    isRed(h.right))     flipColors(h);\n    return h; \n}", 
            "title": "Insertion"
        }, 
        {
            "location": "/2016-01-21/#balance", 
            "text": "Property : The height of the tree is $\\le 2 \\lg N$ in the worst case.", 
            "title": "Balance"
        }, 
        {
            "location": "/2016-01-25/", 
            "text": "Lecture 7 - Notes\n\n\nJanuary 25, 2016\n  \n\n\nBinary Trees\n\n\nHow many nodes in a  binary tree with height $h$?\n\n\n\n\n\\begin{align}\n    h + 1 &\\le n \\newline\n    &\\le 1 + 2 + 4 + ... + 2^h \\newline\n    &= 2^{h+1} - 1\n\\end{align}\n\n\n\n\nand conversely,\n\n\n\n\n\\begin{align}\n    n &\\le 2^{h+1} - 1 \\newline\n    n + 1 &\\le 2^{h+1} \\newline\n    \\lg (n + 1) &\\le h+1 \\newline\n    \\lg (n + 1) - 1 &\\le h \\newline\n    \\left\\lceil\\lg \\left(n + 1\\right) - 1\\right\\rceil &\\le h \\newline\n\\end{align}\n\n\n\n\nBinomial Coefficients\n\n\nLet $n \\choose k$ denote the number of $k$-subsets of an $n$-set. $2$-subsets of the set ${a,b,c,d}$ are\n\n\n\n\n\\begin{align}\n    \\{a,b\\} \\newline\n    \\{a,c\\} \\newline\n    \\{a,d\\} \\newline\n    \\{b,c\\} \\newline\n    \\{b,d\\} \\newline\n    \\{c,d\\} \\newline\n\\end{align}\n\n\n\n\nIn this case,\n\n\n\n\n\\begin{align}\n    \\binom{4}{2} &= 6 \\newline\n    \\binom{4}{1} &= \\binom{4}{3} = 4 \\newline\n\\end{align}\n\n\n\n\nIn general,\n\n\n\n\n\\begin{align}\n    \\binom{n}{k} = \\binom{n}{n-k}\n\\end{align}\n\n\n\n\nthe function $f$ that maps ${a_0,a_1,\\ldots,a_k}$ to $[n] \\setminus {a_0,a_1,\\ldots,a_k}$ where $[n] = {1,2,\\ldots,n}$, is a \nbijection\n. For example\n\n\n\n\n\\begin{align}\n    f\\left(\\left\\{ n \\right\\} \\right) = \\{b,c,d\\}\n\\end{align}\n\n\n\n\nClaim\n: Pascals triangle equality, e.g.,\n\n\n\n\n\\begin{align}\n    \\binom{n}{k} = \\binom{n-1}{k} + \\binom{n-1}{k-1}\n\\end{align}\n\n\n\n\nProof\n: Classify the $k$-subsets of $[n]$ according to whether they contain $n$ or not. There are $\\binom{n-1}{k-1}$ $k$-subsets that contain $n$ and $\\binom{n-1}{k}$ $k$-subsets that do \nnot\n contain $n$.\n\n\nWe can demonstrate this with pascals triangle.\n\n\n\n\n\n\n\n\n\n\n0\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n\n\n\n\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\n\n\n1\n\n\n2\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n\n\n1\n\n\n3\n\n\n3\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n4\n\n\n1\n\n\n4\n\n\n6\n\n\n4\n\n\n1\n\n\n\n\n\n\n\n\n\n\n5\n\n\n1\n\n\n5\n\n\n10\n\n\n10\n\n\n5\n\n\n1\n\n\n\n\n\n\n\n\n6\n\n\n1\n\n\n6\n\n\n15\n\n\n20\n\n\n15\n\n\n6\n\n\n1\n\n\n\n\n\n\n\n\nClaim\n:\n\n\n\n\n\\begin{align}\n    \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\end{align}\n\n\n\n\nShepherd Principal\n: We can prove this using the Shepherd principal. Suppose we are counting sheep and they really like each other so they have squished together into one blob. Luckily the sheep are standing on a sheet of glass so we can go underneath and count the feet. Divide by four and we have the number of sheep.\n\n\nSo if a set (the sheep) has been divided into equivalence classes (the feet) and each equivalence class has the same number for elements. Then the number of equivalence classes is\n\n\n\n\n\\begin{align}\n    \\frac{\\text{Number of Elements}}{\\text{Number in Each Class}}\n\\end{align}\n\n\n\n\nProof\n: There are $n(n-1) \\ldots (n-k+1)$ $k$-sequences in an $n$-set. Each $k$-subset corresponds to $k!$ of these. Thus,\n\n\n\n\n\\begin{align}\n    \\binom{n}{k} &= \\frac{n(n-1) \\ldots (n-k+1)}{k!} \\newline\n    &= \\frac{n(n-1) \\ldots (n-k+1)}{k!} \\cdot \\frac{(n-k)!}{(n-k)!} \\newline\n    &= \\frac{n!}{k!(n-k)!}\\newline\n\\end{align}\n\n\n\n\nExample\n\n\nHow many binary sequences are there with $s$ zeros and $t$ ones? For example, given,\n\n\n\n\n\\begin{align}\n    10101110\n\\end{align}\n\n\n\n\nthen $s = 3$ and $t = 5$.\n\n\nSolution\n\n\nI think the answer is,\n\n\n\n\n\\begin{align}\n    \\binom{s+t}{t}\n\\end{align}\n\n\n\n\nFrank Ruskey is hard to follow at best.\n\n\nBinomial Queues\n\n\ndefinition\n: A \nbinomial queue\n are a kind of a mergeable heap.", 
            "title": "2016 01 25"
        }, 
        {
            "location": "/2016-01-25/#lecture-7-notes", 
            "text": "January 25, 2016", 
            "title": "Lecture 7 - Notes"
        }, 
        {
            "location": "/2016-01-25/#binary-trees", 
            "text": "How many nodes in a  binary tree with height $h$?   \\begin{align}\n    h + 1 &\\le n \\newline\n    &\\le 1 + 2 + 4 + ... + 2^h \\newline\n    &= 2^{h+1} - 1\n\\end{align}   and conversely,   \\begin{align}\n    n &\\le 2^{h+1} - 1 \\newline\n    n + 1 &\\le 2^{h+1} \\newline\n    \\lg (n + 1) &\\le h+1 \\newline\n    \\lg (n + 1) - 1 &\\le h \\newline\n    \\left\\lceil\\lg \\left(n + 1\\right) - 1\\right\\rceil &\\le h \\newline\n\\end{align}", 
            "title": "Binary Trees"
        }, 
        {
            "location": "/2016-01-25/#binomial-coefficients", 
            "text": "Let $n \\choose k$ denote the number of $k$-subsets of an $n$-set. $2$-subsets of the set ${a,b,c,d}$ are   \\begin{align}\n    \\{a,b\\} \\newline\n    \\{a,c\\} \\newline\n    \\{a,d\\} \\newline\n    \\{b,c\\} \\newline\n    \\{b,d\\} \\newline\n    \\{c,d\\} \\newline\n\\end{align}   In this case,   \\begin{align}\n    \\binom{4}{2} &= 6 \\newline\n    \\binom{4}{1} &= \\binom{4}{3} = 4 \\newline\n\\end{align}   In general,   \\begin{align}\n    \\binom{n}{k} = \\binom{n}{n-k}\n\\end{align}   the function $f$ that maps ${a_0,a_1,\\ldots,a_k}$ to $[n] \\setminus {a_0,a_1,\\ldots,a_k}$ where $[n] = {1,2,\\ldots,n}$, is a  bijection . For example   \\begin{align}\n    f\\left(\\left\\{ n \\right\\} \\right) = \\{b,c,d\\}\n\\end{align}   Claim : Pascals triangle equality, e.g.,   \\begin{align}\n    \\binom{n}{k} = \\binom{n-1}{k} + \\binom{n-1}{k-1}\n\\end{align}   Proof : Classify the $k$-subsets of $[n]$ according to whether they contain $n$ or not. There are $\\binom{n-1}{k-1}$ $k$-subsets that contain $n$ and $\\binom{n-1}{k}$ $k$-subsets that do  not  contain $n$.  We can demonstrate this with pascals triangle.      0  1  2  3  4  5  6      0  1          1  1  1         2  1  2  1        3  1  3  3  1       4  1  4  6  4  1      5  1  5  10  10  5  1     6  1  6  15  20  15  6  1     Claim :   \\begin{align}\n    \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\end{align}   Shepherd Principal : We can prove this using the Shepherd principal. Suppose we are counting sheep and they really like each other so they have squished together into one blob. Luckily the sheep are standing on a sheet of glass so we can go underneath and count the feet. Divide by four and we have the number of sheep.  So if a set (the sheep) has been divided into equivalence classes (the feet) and each equivalence class has the same number for elements. Then the number of equivalence classes is   \\begin{align}\n    \\frac{\\text{Number of Elements}}{\\text{Number in Each Class}}\n\\end{align}   Proof : There are $n(n-1) \\ldots (n-k+1)$ $k$-sequences in an $n$-set. Each $k$-subset corresponds to $k!$ of these. Thus,   \\begin{align}\n    \\binom{n}{k} &= \\frac{n(n-1) \\ldots (n-k+1)}{k!} \\newline\n    &= \\frac{n(n-1) \\ldots (n-k+1)}{k!} \\cdot \\frac{(n-k)!}{(n-k)!} \\newline\n    &= \\frac{n!}{k!(n-k)!}\\newline\n\\end{align}", 
            "title": "Binomial Coefficients"
        }, 
        {
            "location": "/2016-01-25/#example", 
            "text": "How many binary sequences are there with $s$ zeros and $t$ ones? For example, given,   \\begin{align}\n    10101110\n\\end{align}   then $s = 3$ and $t = 5$.", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-25/#solution", 
            "text": "I think the answer is,   \\begin{align}\n    \\binom{s+t}{t}\n\\end{align}   Frank Ruskey is hard to follow at best.", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-01-25/#binomial-queues", 
            "text": "definition : A  binomial queue  are a kind of a mergeable heap.", 
            "title": "Binomial Queues"
        }, 
        {
            "location": "/2016-01-28/", 
            "text": "Lecture 8 - Notes\n\n\nJanuary 28, 2016\n  \n\n\nHashing\n\n\ndefinition\n: With \nhashing\n we save items in a key-indexed table (where the index is a function of the key). A \nhash function\n is used for computing the array index from the key.\n\n\nHorner's Rule\n\n\nTo hash a string we use,\n\n\n\n\n\\begin{align}\n    h = s[0] \\cdot 31^{L\u20131} + \\ldots + s[L \u2013 3] \\cdot 31^2 + s[L \u2013 2] \\cdot 31^1 + s[L \u2013 1] \\cdot 31^0\n\\end{align}\n\n\n\n\nfor example,\n\n\npublic final class String\n{\n    private final char[] s;\n    ...\n    public int hashCode()\n    {\n        int hash = 0;\n        for (int i = 0; i \n length(); i++)\n            hash = s[i] + (31 * hash);\n        return hash;\n    }\n}", 
            "title": "2016 01 28"
        }, 
        {
            "location": "/2016-01-28/#lecture-8-notes", 
            "text": "January 28, 2016", 
            "title": "Lecture 8 - Notes"
        }, 
        {
            "location": "/2016-01-28/#hashing", 
            "text": "definition : With  hashing  we save items in a key-indexed table (where the index is a function of the key). A  hash function  is used for computing the array index from the key.", 
            "title": "Hashing"
        }, 
        {
            "location": "/2016-01-28/#horners-rule", 
            "text": "To hash a string we use,   \\begin{align}\n    h = s[0] \\cdot 31^{L\u20131} + \\ldots + s[L \u2013 3] \\cdot 31^2 + s[L \u2013 2] \\cdot 31^1 + s[L \u2013 1] \\cdot 31^0\n\\end{align}   for example,  public final class String\n{\n    private final char[] s;\n    ...\n    public int hashCode()\n    {\n        int hash = 0;\n        for (int i = 0; i   length(); i++)\n            hash = s[i] + (31 * hash);\n        return hash;\n    }\n}", 
            "title": "Horner's Rule"
        }, 
        {
            "location": "/2016-02-01/", 
            "text": "Lecture 9 - Notes\n\n\nFebruary 1, 2016\n  \n\n\nProbability\n\n\nHow many people does it take before the probability that two have the same birthday is more than 50%?\n\n\nLet's assume that all birthdays are equally likely, what's the probability that $n$ people have different birthdays?\n\n\nSo,\n\n\n\n\n\\begin{align}\n    p &= \\frac{\\text{favourable cases}}{\\text{total number of cases}} \\\\\\\\\n    &= \\frac{\\binom{365}{n}n!}{365^n}\n\\end{align}\n\n\n\n\nwe could also think of this as,\n\n\n\n\n\\begin{align}\n    \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot\\frac{365-n}{365}\n\\end{align}\n\n\n\n\nlet's rewrite this where $D$ is the days,\n\n\n\n\n\\begin{align}\n    \\left( 1 - \\frac{0}{D}\\right)\\left( 1 - \\frac{2}{D}\\right)\\ldots\\left( 1 - \\frac{n-1}{D}\\right) = S_n\n\\end{align}\n\n\n\n\nwe're asking when,\n\n\n\n\n\\begin{align}\n    1 - S_n \\ge \\frac{1}{2}\n\\end{align}\n\n\n\n\nNow, when $x$ is small $1 - x \\approx e^x$, so if $n$ is small compared with $D$ then,\n\n\n\n\n\\begin{align}\n    \\prod_{j=1}^{n-1} (1 - \\frac{j}{D}) &\\approx \\prod_{j=1}^{n-1} e^{-\\frac{j}{D}}\\\\\\\\\n    &= e^{\\left( -\\sum_{j=1}^{n-1} \\frac{j}{D} \\right)} \\\\\\\\\n    &= e^{\\left(\\frac{-n\\left( n-1 \\right)}{2D} \\right)} \\\\\\\\\n    &\\approx e^{\\left(\\frac{- n^2}{2D} \\right)} \\\\\\\\\n\\end{align}\n\n\n\n\nso the probability is $\\frac{1}{2}$ when,\n\n\n\n\n\\begin{align}\n    \\frac{n^2}{2D} &= \\ln \\frac{1}{2} \\\\\\\\\n    \\frac{n^2}{2D} &= \\ln 2 \\\\\\\\\n    n &= \\sqrt{2 \\ln 2} \\cdot \\sqrt{D} \\\\\\\\\n    &= \\sqrt{\\ln 4} \\cdot \\sqrt{D} \\\\\\\\\n    &\\approx 1.1774 \\cdot \\sqrt{D} \\\\\\\\\n\\end{align}\n\n\n\n\nHarmonic Numbers\n\n\ndefinition\n: The \nharmonic numbers\n are a series denoted,\n\n\n\n\n\\begin{align}\n    H_n = 1 + \\frac{1}{2} + \\frac{1}{3} + \\ldots + \\frac{1}{n}\n\\end{align}\n\n\n\n\nThe harmonic numbers arise in analyzing many algorithms.\n\n\nExample\n\n\nConsider $f(x) = \\frac{1}{x}$,\n\n\n\n\nMean Time to Failure\n\n\nWhen do you get the first heads when flipping coins?\n\n\nWe can draw the outcomes,\n\n\n\n\nLet $p$ be the probability of a failure (a heads) and $p_k$ be the probability of a failure on the $k$-th try. We can write $p_k$ as\n\n\n\n\n\\begin{align}\n    p_k = \\left( 1 - p \\right)^{k-1}p\n\\end{align}\n\n\n\n\nwhich we can see,\n\n\n\n\n\\begin{align}\n    \\sum_{k \\ge 1} p_k &= \\sum_{k \\ge 1} \\left( 1 - p \\right)^{k-1}p \\\\\\\\\n    &= p \\sum_{k \\ge 0} \\left( 1 - p \\right)^{k} \\\\\\\\\n    &= p \\frac{1}{1-(1-p)} \\\\\\\\\n    &= \\frac{p}{p} \\\\\\\\\n    &= 1 \\\\\\\\\n\\end{align}\n\n\n\n\nso all our probabilities sum to one (which is good).\n\n\nUniform Hashing\n\n\nYou're a coupon collector and you're trying to collect $n$ coupons. How many do I need to collect before I can expect to have them all?\n\n\nLet $X$ be the number of trials.", 
            "title": "2016 02 01"
        }, 
        {
            "location": "/2016-02-01/#lecture-9-notes", 
            "text": "February 1, 2016", 
            "title": "Lecture 9 - Notes"
        }, 
        {
            "location": "/2016-02-01/#probability", 
            "text": "How many people does it take before the probability that two have the same birthday is more than 50%?  Let's assume that all birthdays are equally likely, what's the probability that $n$ people have different birthdays?  So,   \\begin{align}\n    p &= \\frac{\\text{favourable cases}}{\\text{total number of cases}} \\\\\\\\\n    &= \\frac{\\binom{365}{n}n!}{365^n}\n\\end{align}   we could also think of this as,   \\begin{align}\n    \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot\\frac{365-n}{365}\n\\end{align}   let's rewrite this where $D$ is the days,   \\begin{align}\n    \\left( 1 - \\frac{0}{D}\\right)\\left( 1 - \\frac{2}{D}\\right)\\ldots\\left( 1 - \\frac{n-1}{D}\\right) = S_n\n\\end{align}   we're asking when,   \\begin{align}\n    1 - S_n \\ge \\frac{1}{2}\n\\end{align}   Now, when $x$ is small $1 - x \\approx e^x$, so if $n$ is small compared with $D$ then,   \\begin{align}\n    \\prod_{j=1}^{n-1} (1 - \\frac{j}{D}) &\\approx \\prod_{j=1}^{n-1} e^{-\\frac{j}{D}}\\\\\\\\\n    &= e^{\\left( -\\sum_{j=1}^{n-1} \\frac{j}{D} \\right)} \\\\\\\\\n    &= e^{\\left(\\frac{-n\\left( n-1 \\right)}{2D} \\right)} \\\\\\\\\n    &\\approx e^{\\left(\\frac{- n^2}{2D} \\right)} \\\\\\\\\n\\end{align}   so the probability is $\\frac{1}{2}$ when,   \\begin{align}\n    \\frac{n^2}{2D} &= \\ln \\frac{1}{2} \\\\\\\\\n    \\frac{n^2}{2D} &= \\ln 2 \\\\\\\\\n    n &= \\sqrt{2 \\ln 2} \\cdot \\sqrt{D} \\\\\\\\\n    &= \\sqrt{\\ln 4} \\cdot \\sqrt{D} \\\\\\\\\n    &\\approx 1.1774 \\cdot \\sqrt{D} \\\\\\\\\n\\end{align}", 
            "title": "Probability"
        }, 
        {
            "location": "/2016-02-01/#harmonic-numbers", 
            "text": "definition : The  harmonic numbers  are a series denoted,   \\begin{align}\n    H_n = 1 + \\frac{1}{2} + \\frac{1}{3} + \\ldots + \\frac{1}{n}\n\\end{align}   The harmonic numbers arise in analyzing many algorithms.", 
            "title": "Harmonic Numbers"
        }, 
        {
            "location": "/2016-02-01/#example", 
            "text": "Consider $f(x) = \\frac{1}{x}$,", 
            "title": "Example"
        }, 
        {
            "location": "/2016-02-01/#mean-time-to-failure", 
            "text": "When do you get the first heads when flipping coins?  We can draw the outcomes,   Let $p$ be the probability of a failure (a heads) and $p_k$ be the probability of a failure on the $k$-th try. We can write $p_k$ as   \\begin{align}\n    p_k = \\left( 1 - p \\right)^{k-1}p\n\\end{align}   which we can see,   \\begin{align}\n    \\sum_{k \\ge 1} p_k &= \\sum_{k \\ge 1} \\left( 1 - p \\right)^{k-1}p \\\\\\\\\n    &= p \\sum_{k \\ge 0} \\left( 1 - p \\right)^{k} \\\\\\\\\n    &= p \\frac{1}{1-(1-p)} \\\\\\\\\n    &= \\frac{p}{p} \\\\\\\\\n    &= 1 \\\\\\\\\n\\end{align}   so all our probabilities sum to one (which is good).", 
            "title": "Mean Time to Failure"
        }, 
        {
            "location": "/2016-02-01/#uniform-hashing", 
            "text": "You're a coupon collector and you're trying to collect $n$ coupons. How many do I need to collect before I can expect to have them all?  Let $X$ be the number of trials.", 
            "title": "Uniform Hashing"
        }, 
        {
            "location": "/2016-02-04/", 
            "text": "Lecture 10 - Notes\n\n\nFebruary 4, 2016\n  \n\n\nRandom Permutations\n\n\nHow do we generate a random permutation?\n\n\nWe would like it to be uniform with an equal probability of $\\frac{1}{n!}$ for each permutation.\n\n\na = [0,1,2,...,n]\nfor i = n-1, i \n 0, --i\n    t = a[i]\n    j = rand(0,i-1)\n    a[i] = a[j]\n    a[j] = t\n\n\n\n\nwe swap elements on one of the remaining elements in the list, e.g.\n\n\na = [1,2,3,4,5]\n\n  = [5,2,3,4,1]\n     *       ^\n  = [5,2,4,3,1]\n         * ^\n  = [4,2,5,3,1]\n     *   ^\n  = [2,4,5,3,1]\n     * ^\n\n\n\n\nwe can see this is uniform \n\n\n\n\n\\begin{align}\n    \\frac{1}{5} \\cdot \\frac{1}{4} \\cdot \\frac{1}{3} \\cdot \\frac{1}{2} \\cdot  \\frac{1}{1} =  \\frac{1}{5!}\n\\end{align}", 
            "title": "2016 02 04"
        }, 
        {
            "location": "/2016-02-04/#lecture-10-notes", 
            "text": "February 4, 2016", 
            "title": "Lecture 10 - Notes"
        }, 
        {
            "location": "/2016-02-04/#random-permutations", 
            "text": "How do we generate a random permutation?  We would like it to be uniform with an equal probability of $\\frac{1}{n!}$ for each permutation.  a = [0,1,2,...,n]\nfor i = n-1, i   0, --i\n    t = a[i]\n    j = rand(0,i-1)\n    a[i] = a[j]\n    a[j] = t  we swap elements on one of the remaining elements in the list, e.g.  a = [1,2,3,4,5]\n\n  = [5,2,3,4,1]\n     *       ^\n  = [5,2,4,3,1]\n         * ^\n  = [4,2,5,3,1]\n     *   ^\n  = [2,4,5,3,1]\n     * ^  we can see this is uniform    \\begin{align}\n    \\frac{1}{5} \\cdot \\frac{1}{4} \\cdot \\frac{1}{3} \\cdot \\frac{1}{2} \\cdot  \\frac{1}{1} =  \\frac{1}{5!}\n\\end{align}", 
            "title": "Random Permutations"
        }, 
        {
            "location": "/2016-02-15/", 
            "text": "Lecture 11 - Notes\n\n\nFebruary 15, 2016\n  \n\n\nMinimum Weight Spanning Trees\n\n\ndefinition\n: A \nminimum weight spanning tree (MST)\n connects a graph using the lowest possible sum of edge weights.\n\n\nGreedy Algorithms\n\n\nWe make two assumptions,\n\n\n\n\nThe graph is connected\n\n\nEdge weights are distinct (no two edges of the same weight)\n\n\n\n\nThe consequence is that the minimum weight spanning tree exists and is unique.\n\n\nCut Property\n\n\ndefinition\n: If we \ncut\n the graph along any number of edges the edge with the lowest weight will be in the MST.\n\n\nUsing the Cut Property\n\n\n\n\nCut the graph on a set of edges that aren't in the MST yet. \n\n\nAdd the smallest edge to the MST. \n\n\nRepeat until we have $V - 1$ edges in the tree.\n\n\n\n\n\n\nKruskal's Method\n\n\n\n\nGo through the edges from smallest to largest\n\n\nAdd the edge as long as no cycle is created\n\n\n\n\nPrim's Method\n\n\n\n\nStart with vertex 0 and grow the tree $T$\n\n\nStop when we have $V-1$ edges", 
            "title": "2016 02 15"
        }, 
        {
            "location": "/2016-02-15/#lecture-11-notes", 
            "text": "February 15, 2016", 
            "title": "Lecture 11 - Notes"
        }, 
        {
            "location": "/2016-02-15/#minimum-weight-spanning-trees", 
            "text": "definition : A  minimum weight spanning tree (MST)  connects a graph using the lowest possible sum of edge weights.", 
            "title": "Minimum Weight Spanning Trees"
        }, 
        {
            "location": "/2016-02-15/#greedy-algorithms", 
            "text": "We make two assumptions,   The graph is connected  Edge weights are distinct (no two edges of the same weight)   The consequence is that the minimum weight spanning tree exists and is unique.", 
            "title": "Greedy Algorithms"
        }, 
        {
            "location": "/2016-02-15/#cut-property", 
            "text": "definition : If we  cut  the graph along any number of edges the edge with the lowest weight will be in the MST.", 
            "title": "Cut Property"
        }, 
        {
            "location": "/2016-02-15/#using-the-cut-property", 
            "text": "Cut the graph on a set of edges that aren't in the MST yet.   Add the smallest edge to the MST.   Repeat until we have $V - 1$ edges in the tree.", 
            "title": "Using the Cut Property"
        }, 
        {
            "location": "/2016-02-15/#kruskals-method", 
            "text": "Go through the edges from smallest to largest  Add the edge as long as no cycle is created", 
            "title": "Kruskal's Method"
        }, 
        {
            "location": "/2016-02-15/#prims-method", 
            "text": "Start with vertex 0 and grow the tree $T$  Stop when we have $V-1$ edges", 
            "title": "Prim's Method"
        }, 
        {
            "location": "/2016-02-18/", 
            "text": "Lecture 12 - Notes\n\n\nFebruary 18, 2016\n  \n\n\nMinimum Weight Spanning Trees Continued\n\n\nPrim's Algorithm\n\n\n\n\nLazy\n: Keep track of edges in cut\n\n\nEager\n: Keep track of vertices not in tree\n\n\n\n\nIndexed Priority Queues\n\n\nFor the \neager\n algorithm, we implement it with a binary queue. We maintain the arrays,\n\n\n\n\nkeys[i]\n is th priority of \ni\n\n\npq[i]\n is the index of the key in heap position \ni\n\n\nqp[i]\n is the heap position of the key with index \ni", 
            "title": "2016 02 18"
        }, 
        {
            "location": "/2016-02-18/#lecture-12-notes", 
            "text": "February 18, 2016", 
            "title": "Lecture 12 - Notes"
        }, 
        {
            "location": "/2016-02-18/#minimum-weight-spanning-trees-continued", 
            "text": "", 
            "title": "Minimum Weight Spanning Trees Continued"
        }, 
        {
            "location": "/2016-02-18/#prims-algorithm", 
            "text": "Lazy : Keep track of edges in cut  Eager : Keep track of vertices not in tree", 
            "title": "Prim's Algorithm"
        }, 
        {
            "location": "/2016-02-18/#indexed-priority-queues", 
            "text": "For the  eager  algorithm, we implement it with a binary queue. We maintain the arrays,   keys[i]  is th priority of  i  pq[i]  is the index of the key in heap position  i  qp[i]  is the heap position of the key with index  i", 
            "title": "Indexed Priority Queues"
        }, 
        {
            "location": "/2016-02-22/", 
            "text": "Lecture 13 - Notes\n\n\nFebruary 22, 2016\n  \n\n\nUndirected Graphs\n\n\nWe can consider a graph,\n\n\n\n\n\\begin{align}\n    G = (V,E)\n\\end{align}\n\n\n\n\nBipartite Graph\n\n\ndefinition\n: A graph is \nbipartite\n is there is a partition $A,B$ of $V$ such that all edges $(a,b) \\in E$ have $a \\in A$ and $b \\in B$.\n\n\nTrees are an example of a bipartite set, we can show this using a \ntwo coloring\n. So are paths, even cycles, and complete bipartite graphs.\n\n\nSubgraphs\n\n\ndefinition\n: A graph $G^\\prime$ is a \nsubgraph\n of a graph $G$ if $V^\\prime \\subseteq V$, $E^\\prime \\subseteq E$ and all edges in $E^\\prime$ are valid.\n\n\nThere are a few special types of subgraphs,\n\n\n\n\nspanning\n: Uses all the vertices in $G$, i.e., $V^\\prime = V$\n\n\ninduced\n: Uses all the valid edges in $G$ (with the selected vertices)", 
            "title": "2016 02 22"
        }, 
        {
            "location": "/2016-02-22/#lecture-13-notes", 
            "text": "February 22, 2016", 
            "title": "Lecture 13 - Notes"
        }, 
        {
            "location": "/2016-02-22/#undirected-graphs", 
            "text": "We can consider a graph,   \\begin{align}\n    G = (V,E)\n\\end{align}", 
            "title": "Undirected Graphs"
        }, 
        {
            "location": "/2016-02-22/#bipartite-graph", 
            "text": "definition : A graph is  bipartite  is there is a partition $A,B$ of $V$ such that all edges $(a,b) \\in E$ have $a \\in A$ and $b \\in B$.  Trees are an example of a bipartite set, we can show this using a  two coloring . So are paths, even cycles, and complete bipartite graphs.", 
            "title": "Bipartite Graph"
        }, 
        {
            "location": "/2016-02-22/#subgraphs", 
            "text": "definition : A graph $G^\\prime$ is a  subgraph  of a graph $G$ if $V^\\prime \\subseteq V$, $E^\\prime \\subseteq E$ and all edges in $E^\\prime$ are valid.  There are a few special types of subgraphs,   spanning : Uses all the vertices in $G$, i.e., $V^\\prime = V$  induced : Uses all the valid edges in $G$ (with the selected vertices)", 
            "title": "Subgraphs"
        }, 
        {
            "location": "/2016-02-29/", 
            "text": "Lecture 14 - Notes\n\n\nFebruary 29, 2016\n  \n\n\nEulerian Cycle\n\n\ncontains every edge once\n\n\n\n\nthe origins of graph theory, bridges of Konigsberg\n\n\n\n\n\n\n\n\nsee \nwikipedia article\n\n\n\n\nHamilton Cycle\n\n\nContains every vertex once\n\n\nSome Theorems\n\n\n\n\nA undirected graph has a Eulerian cycle iff every vertex has even degree\n\n\nA directed graph has a Eulerian Path iff exactly 2 vertices have odd degrees", 
            "title": "2016 02 29"
        }, 
        {
            "location": "/2016-02-29/#lecture-14-notes", 
            "text": "February 29, 2016", 
            "title": "Lecture 14 - Notes"
        }, 
        {
            "location": "/2016-02-29/#eulerian-cycle", 
            "text": "contains every edge once   the origins of graph theory, bridges of Konigsberg     see  wikipedia article", 
            "title": "Eulerian Cycle"
        }, 
        {
            "location": "/2016-02-29/#hamilton-cycle", 
            "text": "Contains every vertex once", 
            "title": "Hamilton Cycle"
        }, 
        {
            "location": "/2016-02-29/#some-theorems", 
            "text": "A undirected graph has a Eulerian cycle iff every vertex has even degree  A directed graph has a Eulerian Path iff exactly 2 vertices have odd degrees", 
            "title": "Some Theorems"
        }, 
        {
            "location": "/2016-03-03/", 
            "text": "Lecture 15 - Notes\n\n\nMarch 3, 2016\n  \n\n\nEulerian Cycles\n\n\ndefinition\n: A \nEulerian Cycle\n contains all the edges in the graph exactly once.\n\n\nTheorem\n\n\nA connected indirected graph has an Eulerian cycle if and only if the degree of each vertex is even.\n\n\nTheorem\n\n\nA connected (strongly connected) digraph has an Eulerian cycle if and only if the in-degree of each vertex equals its out-degree.\n\n\nAlgorithm\n\n\nTo find the Euclidean cycle in a digraph (enumerate the edges in the cycle), using a greedy process,\n\n\n\n\nPreprocess the graph and make and in-tree with root $r$, compute $\\bar{G}$ (reverse all edges). Then perform BFS to get the tree $T$. This is $O(|E| + |V|)$.\n\n\n\n\n\n\nif we write the adjacency list for the graph,\n\n\n\n\n\\begin{aligned}\n    r &\\to d\\\\\\\\\n    a &\\to b \\to r \\\\\\\\\n    b &\\to c \\\\\\\\\n    c &\\to d \\to a \\\\\\\\\n    d &\\to a \\to c \\\\\\\\\n\\end{aligned}\n\n\n\n\nWhen we perform the algorithm, we'll get the list,\n\n\n\n\n\\begin{aligned}\n    r \\to d \\to a \\to a \\to b \\to c \\to d \\to c \\to a \\to r\n\\end{aligned}\n\n\n\n\nWhy does it work?\n This works because, since, $G$ is Eulerian the algorithm ends at $r$. Imagine that $(v,w)$ is missing . Since the algorithm terminated $v \\neq r$. Without loss of generality we can assume that $(v,w) \\in T$. Since $C - P$ is balanced (where $P$ is the cycle found) there is an edge $(u,v)$ also not in $P$. Without loss of generality $(u,v) \\in T$. Continuing in this manner we get a sequence of tree edges which eventually get back to $r$, a contradiction.\n\n\nThis is actually what Frank Rusky wrote on the board. He makes no sense.\n\n\nEfficiency\n\n\nWe can get all edges in $O(|E| + |V|)$.\n\n\nHamiltonian Cycles\n\n\nFinding all vertices in a Hamiltonian is an $nP$-complete problem.\n\n\nPlanar Graphs\n\n\ndefinition\n: A graph is \nplanar\n if there is a way to embedded it in the plane (drawn in two dimensions) without crossing edges. The graph embedded in the plane is a \nplane graph\n however a graph can be planar without being a plane graph. For example edges could be crossed but it has the potential to be rewritten into a plane graph.\n\n\nAre Two Graphs Isomorphic?\n\n\ndefinition\n: Two graphs are \nisomorphic\n if there is a bijection $\\phi: V \\to V^\\prime$ such that for every edge in $V$,\n\n\n\n\n\\begin{aligned}\n    (v,w) \\in E \\iff (\\phi(v),\\phi(w)) \\in E\n\\end{aligned}", 
            "title": "2016 03 03"
        }, 
        {
            "location": "/2016-03-03/#lecture-15-notes", 
            "text": "March 3, 2016", 
            "title": "Lecture 15 - Notes"
        }, 
        {
            "location": "/2016-03-03/#eulerian-cycles", 
            "text": "definition : A  Eulerian Cycle  contains all the edges in the graph exactly once.", 
            "title": "Eulerian Cycles"
        }, 
        {
            "location": "/2016-03-03/#theorem", 
            "text": "A connected indirected graph has an Eulerian cycle if and only if the degree of each vertex is even.", 
            "title": "Theorem"
        }, 
        {
            "location": "/2016-03-03/#theorem_1", 
            "text": "A connected (strongly connected) digraph has an Eulerian cycle if and only if the in-degree of each vertex equals its out-degree.", 
            "title": "Theorem"
        }, 
        {
            "location": "/2016-03-03/#algorithm", 
            "text": "To find the Euclidean cycle in a digraph (enumerate the edges in the cycle), using a greedy process,   Preprocess the graph and make and in-tree with root $r$, compute $\\bar{G}$ (reverse all edges). Then perform BFS to get the tree $T$. This is $O(|E| + |V|)$.    if we write the adjacency list for the graph,   \\begin{aligned}\n    r &\\to d\\\\\\\\\n    a &\\to b \\to r \\\\\\\\\n    b &\\to c \\\\\\\\\n    c &\\to d \\to a \\\\\\\\\n    d &\\to a \\to c \\\\\\\\\n\\end{aligned}   When we perform the algorithm, we'll get the list,   \\begin{aligned}\n    r \\to d \\to a \\to a \\to b \\to c \\to d \\to c \\to a \\to r\n\\end{aligned}   Why does it work?  This works because, since, $G$ is Eulerian the algorithm ends at $r$. Imagine that $(v,w)$ is missing . Since the algorithm terminated $v \\neq r$. Without loss of generality we can assume that $(v,w) \\in T$. Since $C - P$ is balanced (where $P$ is the cycle found) there is an edge $(u,v)$ also not in $P$. Without loss of generality $(u,v) \\in T$. Continuing in this manner we get a sequence of tree edges which eventually get back to $r$, a contradiction.  This is actually what Frank Rusky wrote on the board. He makes no sense.", 
            "title": "Algorithm"
        }, 
        {
            "location": "/2016-03-03/#efficiency", 
            "text": "We can get all edges in $O(|E| + |V|)$.", 
            "title": "Efficiency"
        }, 
        {
            "location": "/2016-03-03/#hamiltonian-cycles", 
            "text": "Finding all vertices in a Hamiltonian is an $nP$-complete problem.", 
            "title": "Hamiltonian Cycles"
        }, 
        {
            "location": "/2016-03-03/#planar-graphs", 
            "text": "definition : A graph is  planar  if there is a way to embedded it in the plane (drawn in two dimensions) without crossing edges. The graph embedded in the plane is a  plane graph  however a graph can be planar without being a plane graph. For example edges could be crossed but it has the potential to be rewritten into a plane graph.", 
            "title": "Planar Graphs"
        }, 
        {
            "location": "/2016-03-03/#are-two-graphs-isomorphic", 
            "text": "definition : Two graphs are  isomorphic  if there is a bijection $\\phi: V \\to V^\\prime$ such that for every edge in $V$,   \\begin{aligned}\n    (v,w) \\in E \\iff (\\phi(v),\\phi(w)) \\in E\n\\end{aligned}", 
            "title": "Are Two Graphs Isomorphic?"
        }, 
        {
            "location": "/2016-03-07/", 
            "text": "Lecture 16 - Notes\n\n\nMarch 7, 2016\n  \n\n\nPlanar Graphs Continued\n\n\nEuler Relation\n\n\ndefinition\n: The \nEuler Relation\n is, given a planar graph,\n\n\n\n\n\\begin{aligned}\n    f + v = e + 2\n\\end{aligned}\n\n\n\n\nwhere $f$ is the number of faces, $v$ is the number of vertices and $e$ is the number of edges.\n\n\nProof\n\n\nImagine we're invading Rome and we want to first flood all the fields around Rome then destroy all roads leading to Rome. How many edges do we destroy? \n\n\nTo flood the regions we need to break a dyke leading into every region, so $f-1$ dykes (edges in this case).\n\n\nTo destroy the roads we have to destroy $v - 1$ roads.\n\n\nSo,\n\n\n\n\n\\begin{gathered}\n    (f-1) + (v-1) = e \\\\\\\\\n    \\downarrow \\\\\\\\\n    f + v = e + 2 \\\\\\\\\n\\end{gathered}\n\n\n\n\nGeometric Dual\n\n\ndefinition\n: We define the \nGeometric Dual\n of a planar graph $G$ as the graph created if we make a vertex out of every face of $G$.\n\n\n\n\nIf all faces are incident on at least $3$ edges then,\n\n\n\n\n\\begin{gathered}\n    3f \\le 2e \\\\\\\\\n    \\downarrow \\\\\\\\\n    3e + 6 = 3v + 3f \\le 3v + 3e \\\\\\\\\n    e \\le 3v - 6\n\\end{gathered}\n\n\n\n\nTheorem\n\n\nIf a Planar Graph without self-loops or multi-edges,\n\n\n\n\n\\begin{aligned}\n    e \\le 3v - 6\n\\end{aligned}\n\n\n\n\nGenus\n\n\ndefinition\n: The \nGenus\n of a graph is defined as the degree of the surface required to embed the graph on the surface. It is related to the graph by,\n\n\n\n\n\\begin{aligned}\n    \\text{genus} &= \\frac{1}{2} \\left( 2 - v + e - f \\right)\n\\end{aligned}\n\n\n\n\nHere's some examples of different genus,\n\n\n\n\n\n\n\n\nGenus 0\n\n\nGenus 1\n\n\nGenus 2\n\n\nGenus 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmbedding in a Plane\n\n\nPre-Processing\n\n\n\n\nBreak a Graph into its connected components\n\n\nBreak each component down to 2-connected components (subgraphs with no cut vertices)", 
            "title": "2016 03 07"
        }, 
        {
            "location": "/2016-03-07/#lecture-16-notes", 
            "text": "March 7, 2016", 
            "title": "Lecture 16 - Notes"
        }, 
        {
            "location": "/2016-03-07/#planar-graphs-continued", 
            "text": "", 
            "title": "Planar Graphs Continued"
        }, 
        {
            "location": "/2016-03-07/#euler-relation", 
            "text": "definition : The  Euler Relation  is, given a planar graph,   \\begin{aligned}\n    f + v = e + 2\n\\end{aligned}   where $f$ is the number of faces, $v$ is the number of vertices and $e$ is the number of edges.", 
            "title": "Euler Relation"
        }, 
        {
            "location": "/2016-03-07/#proof", 
            "text": "Imagine we're invading Rome and we want to first flood all the fields around Rome then destroy all roads leading to Rome. How many edges do we destroy?   To flood the regions we need to break a dyke leading into every region, so $f-1$ dykes (edges in this case).  To destroy the roads we have to destroy $v - 1$ roads.  So,   \\begin{gathered}\n    (f-1) + (v-1) = e \\\\\\\\\n    \\downarrow \\\\\\\\\n    f + v = e + 2 \\\\\\\\\n\\end{gathered}", 
            "title": "Proof"
        }, 
        {
            "location": "/2016-03-07/#geometric-dual", 
            "text": "definition : We define the  Geometric Dual  of a planar graph $G$ as the graph created if we make a vertex out of every face of $G$.   If all faces are incident on at least $3$ edges then,   \\begin{gathered}\n    3f \\le 2e \\\\\\\\\n    \\downarrow \\\\\\\\\n    3e + 6 = 3v + 3f \\le 3v + 3e \\\\\\\\\n    e \\le 3v - 6\n\\end{gathered}", 
            "title": "Geometric Dual"
        }, 
        {
            "location": "/2016-03-07/#theorem", 
            "text": "If a Planar Graph without self-loops or multi-edges,   \\begin{aligned}\n    e \\le 3v - 6\n\\end{aligned}", 
            "title": "Theorem"
        }, 
        {
            "location": "/2016-03-07/#genus", 
            "text": "definition : The  Genus  of a graph is defined as the degree of the surface required to embed the graph on the surface. It is related to the graph by,   \\begin{aligned}\n    \\text{genus} &= \\frac{1}{2} \\left( 2 - v + e - f \\right)\n\\end{aligned}   Here's some examples of different genus,     Genus 0  Genus 1  Genus 2  Genus 3", 
            "title": "Genus"
        }, 
        {
            "location": "/2016-03-07/#embedding-in-a-plane", 
            "text": "Pre-Processing   Break a Graph into its connected components  Break each component down to 2-connected components (subgraphs with no cut vertices)", 
            "title": "Embedding in a Plane"
        }, 
        {
            "location": "/2016-03-10/", 
            "text": "Lecture 17 - Notes\n\n\nMarch 10, 2016\n  \n\n\nShortest Path Algorithms\n\n\ndefinition\n: Given a directed edge-weighted graph, find the \nshortest path\n from $s$ to $w$.\n\n\nWe begin by setting the distance to $s$ to $0$ and the distance to $w$ to $\\infty$ for all other vertices $v$. We  \nrelax\n an when we evaluate the actual shortest path from that node to $w$.\n\n\nDijkstra's Algorithm\n\n\ndefinition\n: To find the shortest path between $a$ and $b$. Pick the unvisited vertex with the lowest distance and calculate the distance through it to each unvisited neighbour, then update the neighbour's distance if smaller. Mark the vertex visited (or red) when done with neighbours.\n\n\n\n\nDirected Acyclic Graph\n\n\nOn a directed acyclic graph the algorithm takes $O(E+V)$.", 
            "title": "2016 03 10"
        }, 
        {
            "location": "/2016-03-10/#lecture-17-notes", 
            "text": "March 10, 2016", 
            "title": "Lecture 17 - Notes"
        }, 
        {
            "location": "/2016-03-10/#shortest-path-algorithms", 
            "text": "definition : Given a directed edge-weighted graph, find the  shortest path  from $s$ to $w$.  We begin by setting the distance to $s$ to $0$ and the distance to $w$ to $\\infty$ for all other vertices $v$. We   relax  an when we evaluate the actual shortest path from that node to $w$.", 
            "title": "Shortest Path Algorithms"
        }, 
        {
            "location": "/2016-03-10/#dijkstras-algorithm", 
            "text": "definition : To find the shortest path between $a$ and $b$. Pick the unvisited vertex with the lowest distance and calculate the distance through it to each unvisited neighbour, then update the neighbour's distance if smaller. Mark the vertex visited (or red) when done with neighbours.", 
            "title": "Dijkstra's Algorithm"
        }, 
        {
            "location": "/2016-03-10/#directed-acyclic-graph", 
            "text": "On a directed acyclic graph the algorithm takes $O(E+V)$.", 
            "title": "Directed Acyclic Graph"
        }, 
        {
            "location": "/2016-03-14/", 
            "text": "Lecture 18 - Notes\n\n\nMarch 14, 2016\n  \n\n\nShortest Path Algorithms Continued\n\n\nFloyd-Warshall Algorithm\n\n\ndefinition\n: To find the shortest path between all pairs \nd[n][n]\n and make a shortest distance matrix. Let $d_{ij}^{(k)}$ be the shortest path from $i$ to $j$ passing through vertices, $1,2,...,k$. The algorithm states,\n\n\n\n\n\\begin{aligned}\n    d_{ij}^{(k)} = \\min(d_{ij}^{(k-1)},d_{ik}^{(k-1)} + d_{kj}^{(k-1)})\n\\end{aligned}", 
            "title": "2016 03 14"
        }, 
        {
            "location": "/2016-03-14/#lecture-18-notes", 
            "text": "March 14, 2016", 
            "title": "Lecture 18 - Notes"
        }, 
        {
            "location": "/2016-03-14/#shortest-path-algorithms-continued", 
            "text": "", 
            "title": "Shortest Path Algorithms Continued"
        }, 
        {
            "location": "/2016-03-14/#floyd-warshall-algorithm", 
            "text": "definition : To find the shortest path between all pairs  d[n][n]  and make a shortest distance matrix. Let $d_{ij}^{(k)}$ be the shortest path from $i$ to $j$ passing through vertices, $1,2,...,k$. The algorithm states,   \\begin{aligned}\n    d_{ij}^{(k)} = \\min(d_{ij}^{(k-1)},d_{ik}^{(k-1)} + d_{kj}^{(k-1)})\n\\end{aligned}", 
            "title": "Floyd-Warshall Algorithm"
        }, 
        {
            "location": "/2016-03-17/", 
            "text": "Lecture 19 - Notes\n\n\nMarch 17, 2016\n  \n\n\nShortest Path Algorithms Continued\n\n\nBellman-Ford\n\n\ndefinition\n: We begin by setting the distance to $s$ to $0$ and the distance to $w$ to $\\infty$ for all other vertices $v$. We relax \nevery\n node $E$ exactly $V$ times.\n\n\nDynamic Programming\n\n\ndefinition\n: Like greedy, \nDynamic Programming\n is a problem solving technique particularly applicable to optimization. An example would be the Floyd-Warshall All-Pairs Shortest Path Algorithm.\n\n\nSuppose I create a variable,\n\n\n\n\n\\begin{aligned}\n    d_{i}^{(k)} = \\min\\left(d_{i}^{(k-1)}, \\min_{j \\in E}\\left( d_{j}^{(k-1)} + w_{ij} \\right) \\right)\n\\end{aligned}\n\n\n\n\nwhere $d_{i}^{(k)}$ is the shortest path from $s$ to $i$ using at most $k$ edges. This is an example of the Bellman-Ford algorithm.\n\n\nLongest Common Substring\n\n\ndefinition\n: Given two strings, $S_1$ and $S_2$, what is their longest common substring? It's possible we could allow skipping letters in the the strings.\n\n\nWe can solve this using dynamic programming, let's call our strings,\n\n\n\n\n\\begin{aligned}\n    x &= x_1 x_2 x_3 \\ldots x_n \\\\\\\\\n    y &= y_1 y_2 y_3 \\ldots y_m \\\\\\\\\n\\end{aligned}\n\n\n\n\nand,\n\n\n\n\n\\begin{aligned}\n    c[i,j] &=\n    \\begin{cases}\n        0 & \\text{if}~ i=0 ~\\text{or}~ j=0 \\\\\\\\\n        1 + c[i -1,j-1] & \\text{if}~ x_i = y_i \\\\\\\\\n        \\max\\left(c[i-1,j], c[i,j-1] \\right) & \\text{if}~ x_i \\neq y_i \\\\\\\\\n    \\end{cases} \\\\\\\\\n    &~\n\\end{aligned}\n\n\n\n\nwhere $c[i,j]$ is the longest common string of $x[1 \\ldots i]$ and  $y[1 \\ldots j]$.", 
            "title": "2016 03 17"
        }, 
        {
            "location": "/2016-03-17/#lecture-19-notes", 
            "text": "March 17, 2016", 
            "title": "Lecture 19 - Notes"
        }, 
        {
            "location": "/2016-03-17/#shortest-path-algorithms-continued", 
            "text": "", 
            "title": "Shortest Path Algorithms Continued"
        }, 
        {
            "location": "/2016-03-17/#bellman-ford", 
            "text": "definition : We begin by setting the distance to $s$ to $0$ and the distance to $w$ to $\\infty$ for all other vertices $v$. We relax  every  node $E$ exactly $V$ times.", 
            "title": "Bellman-Ford"
        }, 
        {
            "location": "/2016-03-17/#dynamic-programming", 
            "text": "definition : Like greedy,  Dynamic Programming  is a problem solving technique particularly applicable to optimization. An example would be the Floyd-Warshall All-Pairs Shortest Path Algorithm.  Suppose I create a variable,   \\begin{aligned}\n    d_{i}^{(k)} = \\min\\left(d_{i}^{(k-1)}, \\min_{j \\in E}\\left( d_{j}^{(k-1)} + w_{ij} \\right) \\right)\n\\end{aligned}   where $d_{i}^{(k)}$ is the shortest path from $s$ to $i$ using at most $k$ edges. This is an example of the Bellman-Ford algorithm.", 
            "title": "Dynamic Programming"
        }, 
        {
            "location": "/2016-03-17/#longest-common-substring", 
            "text": "definition : Given two strings, $S_1$ and $S_2$, what is their longest common substring? It's possible we could allow skipping letters in the the strings.  We can solve this using dynamic programming, let's call our strings,   \\begin{aligned}\n    x &= x_1 x_2 x_3 \\ldots x_n \\\\\\\\\n    y &= y_1 y_2 y_3 \\ldots y_m \\\\\\\\\n\\end{aligned}   and,   \\begin{aligned}\n    c[i,j] &=\n    \\begin{cases}\n        0 & \\text{if}~ i=0 ~\\text{or}~ j=0 \\\\\\\\\n        1 + c[i -1,j-1] & \\text{if}~ x_i = y_i \\\\\\\\\n        \\max\\left(c[i-1,j], c[i,j-1] \\right) & \\text{if}~ x_i \\neq y_i \\\\\\\\\n    \\end{cases} \\\\\\\\\n    &~\n\\end{aligned}   where $c[i,j]$ is the longest common string of $x[1 \\ldots i]$ and  $y[1 \\ldots j]$.", 
            "title": "Longest Common Substring"
        }, 
        {
            "location": "/2016-03-21/", 
            "text": "Lecture 20 - Notes\n\n\nMarch 21, 2016\n  \n\n\nBacktracking\n\n\ndefinition\n: \nBacktracking\n is a general technique for,\n\n\n\n\nexhaustive generation\n\n\nsearches in large discrete space", 
            "title": "2016 03 21"
        }, 
        {
            "location": "/2016-03-21/#lecture-20-notes", 
            "text": "March 21, 2016", 
            "title": "Lecture 20 - Notes"
        }, 
        {
            "location": "/2016-03-21/#backtracking", 
            "text": "definition :  Backtracking  is a general technique for,   exhaustive generation  searches in large discrete space", 
            "title": "Backtracking"
        }
    ]
}